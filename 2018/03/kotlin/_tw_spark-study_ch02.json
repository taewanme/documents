{"paragraphs":[{"text":"%md\n# 스칼라와 스파크를 활용한 데이터 분석","user":"anonymous","dateUpdated":"Mar 14, 2018 2:15:14 PM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":"true"},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>스칼라와 스파크를 활용한 데이터 분석</h1>\n</div>"}]},"apps":[],"jobName":"paragraph_1521008261103_-1108360992","id":"20180314-061741_1674031127","dateCreated":"Mar 14, 2018 6:17:41 AM","dateStarted":"Mar 14, 2018 2:15:14 PM","dateFinished":"Mar 14, 2018 2:15:14 PM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"%md\n- Garbage in, Garbase out\n- 데이터 과학자의 소질\n    - 데이터 모든 단계에서 흥미롭고 가치있는 문제를 찾아내는 능력\n    - 문제를 발굴하고 도출하는 능력\n- 현실: 데이터 과학자에게 데이터 품질을 맡기는 것\n    - 아이들에게 채소를 먹으라고 이야기하는 것은 쉽다.\n","user":"anonymous","dateUpdated":"Mar 14, 2018 6:21:30 AM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":"true"},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<ul>\n  <li>Garbage in, Garbase out</li>\n  <li>데이터 과학자의 소질\n    <ul>\n      <li>데이터 모든 단계에서 흥미롭고 가치있는 문제를 찾아내는 능력</li>\n      <li>문제를 발굴하고 도출하는 능력</li>\n    </ul>\n  </li>\n  <li>현실: 데이터 과학자에게 데이터 품질을 맡기는 것\n    <ul>\n      <li>아이들에게 채소를 먹으라고 이야기하는 것은 쉽다.</li>\n    </ul>\n  </li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1521008221052_-424875091","id":"20180314-061701_421353874","dateCreated":"Mar 14, 2018 6:17:01 AM","dateStarted":"Mar 14, 2018 6:21:30 AM","dateFinished":"Mar 14, 2018 6:21:30 AM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"%md\n## 2.1 데이터 과학자를 위한 스칼라","user":"anonymous","dateUpdated":"Mar 14, 2018 6:21:52 AM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>2.1 데이터 과학자를 위한 스칼라</h2>\n</div>"}]},"apps":[],"jobName":"paragraph_1521008496558_-2115463403","id":"20180314-062136_1936876968","dateCreated":"Mar 14, 2018 6:21:36 AM","dateStarted":"Mar 14, 2018 6:21:52 AM","dateFinished":"Mar 14, 2018 6:21:52 AM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"%md\n- spark은 소프트웨어 스택이다. \n    - 로컬과 분산에서 동일하게 동작하는 spark\n    - spark sql\n    - spark streaming\n","user":"anonymous","dateUpdated":"Mar 14, 2018 6:24:16 AM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala","editorHide":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<ul>\n  <li>spark은 소프트웨어 스택이다.\n    <ul>\n      <li>로컬과 분산에서 동일하게 동작하는 spark</li>\n      <li>spark sql</li>\n      <li>spark streaming</li>\n    </ul>\n  </li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1521008295351_187904024","id":"20180314-061815_29409869","dateCreated":"Mar 14, 2018 6:18:15 AM","dateStarted":"Mar 14, 2018 6:24:13 AM","dateFinished":"Mar 14, 2018 6:24:13 AM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"%md\n- Recocde Linkage(레코드 링크)\n    - 동의어\n        - Entity Resolution\n        - Recode Deduplication\n        - Merge-and-Purge\n    - 같은 실체를 가리티는 레코드를 연결 짓는 것","user":"anonymous","dateUpdated":"Mar 15, 2018 12:54:12 AM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":"true"},"editorMode":"ace/mode/markdown","editorHide":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<ul>\n  <li>Recocde Linkage(레코드 링크)\n    <ul>\n      <li>동의어\n        <ul>\n          <li>Entity Resolution</li>\n          <li>Recode Deduplication</li>\n          <li>Merge-and-Purge</li>\n        </ul>\n      </li>\n      <li>같은 실체를 가리티는 레코드를 연결 짓는 것</li>\n    </ul>\n  </li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1521008652988_327321044","id":"20180314-062412_731561019","dateCreated":"Mar 14, 2018 6:24:12 AM","dateStarted":"Mar 14, 2018 6:27:36 AM","dateFinished":"Mar 14, 2018 6:27:36 AM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"%md\n## 실습 데이터 확보\n\n- UC 어바인 머신러닝 데이터 저장소\n    - UC Irvine Machine Learning Repository\n    - 2010년 독일 병원에서 실시한 데이터 링크 연구 데이터\n    - 데이터 수: 수백만 건\n    - 속성\n        - 환자 성, 이름\n        - 주소\n        - 생일\n        - 문자열 유사도 : 0.0 ~ 1.0","user":"anonymous","dateUpdated":"Mar 14, 2018 8:09:04 AM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala","editorHide":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>실습 데이터 확보</h2>\n<ul>\n  <li>UC 어바인 머신러닝 데이터 저장소\n    <ul>\n      <li>UC Irvine Machine Learning Repository</li>\n      <li>2010년 독일 병원에서 실시한 데이터 링크 연구 데이터</li>\n      <li>데이터 수: 수백만 건</li>\n      <li>속성\n        <ul>\n          <li>환자 성, 이름</li>\n          <li>주소</li>\n          <li>생일</li>\n          <li>문자열 유사도 : 0.0 ~ 1.0</li>\n        </ul>\n      </li>\n    </ul>\n  </li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1521008856667_-1868553655","id":"20180314-062736_1033278228","dateCreated":"Mar 14, 2018 6:27:36 AM","dateStarted":"Mar 14, 2018 8:09:01 AM","dateFinished":"Mar 14, 2018 8:09:01 AM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"%md\n## 데이터 다운로드\n","user":"anonymous","dateUpdated":"Mar 14, 2018 8:34:51 AM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"text","editOnDblClick":false},"editorMode":"ace/mode/text","editorHide":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>데이터 다운로드</h2>\n</div>"}]},"apps":[],"jobName":"paragraph_1521016478561_-1304261197","id":"20180314-083438_1904934464","dateCreated":"Mar 14, 2018 8:34:38 AM","dateStarted":"Mar 14, 2018 8:34:48 AM","dateFinished":"Mar 14, 2018 8:34:48 AM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"%sh\necho \"--------------------------------\"\necho \"----unzip file\"\necho \"--------------------------------\"\ncd /var/lib/zeppelin/workspace/taewan/linkage\nunzip donation.zip\nunzip '*.zip'\nrm -f block_*.zip\n","user":"anonymous","dateUpdated":"Mar 14, 2018 8:39:59 AM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"sh","editOnDblClick":"false"},"editorMode":"ace/mode/sh","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"--------------------------------\n----unzip file\n--------------------------------\nArchive:  donation.zip\n extracting: block_10.zip            \n extracting: block_1.zip             \n extracting: block_2.zip             \n extracting: block_3.zip             \n extracting: block_4.zip             \n extracting: block_5.zip             \n extracting: block_6.zip             \n extracting: block_7.zip             \n extracting: block_8.zip             \n extracting: block_9.zip             \nreplace documentation? [y]es, [n]o, [A]ll, [N]one, [r]ename:  NULL\n(EOF or read error, treating as \"[N]one\" ...)\nArchive:  block_8.zip\n\nArchive:  block_9.zip\n\nArchive:  block_3.zip\n\nArchive:  block_7.zip\n\nArchive:  block_2.zip\n\nArchive:  block_6.zip\n\nArchive:  block_10.zip\n\nArchive:  block_5.zip\n\nArchive:  block_1.zip\n\nArchive:  block_4.zip\n\nArchive:  donation.zip\nreplace block_8.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename:  NULL\n(EOF or read error, treating as \"[N]one\" ...)\n\n10 archives were successfully processed.\n1 archive had warnings but no fatal errors.\n"}]},"apps":[],"jobName":"paragraph_1521015284844_-715836157","id":"20180314-081444_1281055567","dateCreated":"Mar 14, 2018 8:14:44 AM","dateStarted":"Mar 14, 2018 8:39:57 AM","dateFinished":"Mar 14, 2018 8:39:57 AM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"%sh\ncd /var/lib/zeppelin/workspace/taewan/linkage\necho \"--------------------------------\"\necho \"----List of data files\"\necho \"--------------------------------\"\nls -al *.csv","user":"anonymous","dateUpdated":"Mar 14, 2018 8:40:06 AM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"sh","editOnDblClick":"false"},"editorMode":"ace/mode/sh","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"--------------------------------\n----List of data files\n--------------------------------\n-rw-r--r-- 1 zeppelin zeppelin 26255957 Mar  9  2011 block_10.csv\n-rw-r--r-- 1 zeppelin zeppelin 26248574 Mar  9  2011 block_1.csv\n-rw-r--r-- 1 zeppelin zeppelin 26241784 Mar  9  2011 block_2.csv\n-rw-r--r-- 1 zeppelin zeppelin 26253247 Mar  9  2011 block_3.csv\n-rw-r--r-- 1 zeppelin zeppelin 26247471 Mar  9  2011 block_4.csv\n-rw-r--r-- 1 zeppelin zeppelin 26249424 Mar  9  2011 block_5.csv\n-rw-r--r-- 1 zeppelin zeppelin 26256126 Mar  9  2011 block_6.csv\n-rw-r--r-- 1 zeppelin zeppelin 26261911 Mar  9  2011 block_7.csv\n-rw-r--r-- 1 zeppelin zeppelin 26253911 Mar  9  2011 block_8.csv\n-rw-r--r-- 1 zeppelin zeppelin 26254012 Mar  9  2011 block_9.csv\n-rw-r--r-- 1 zeppelin zeppelin      272 Mar  9  2011 frequencies.csv\n"}]},"apps":[],"jobName":"paragraph_1521016034594_-1253289332","id":"20180314-082714_1402284914","dateCreated":"Mar 14, 2018 8:27:14 AM","dateStarted":"Mar 14, 2018 8:40:03 AM","dateFinished":"Mar 14, 2018 8:40:03 AM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"%md\n### 하둡 디렉터리 정리","user":"anonymous","dateUpdated":"Mar 14, 2018 9:30:29 AM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":"true"},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>하둡 디렉터리 정리</h3>\n</div>"}]},"apps":[],"jobName":"paragraph_1521019806774_-2013392291","id":"20180314-093006_394172212","dateCreated":"Mar 14, 2018 9:30:06 AM","dateStarted":"Mar 14, 2018 9:30:29 AM","dateFinished":"Mar 14, 2018 9:30:29 AM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"%sh\nhadoop fs -rmr taewan","user":"anonymous","dateUpdated":"Mar 14, 2018 9:31:46 AM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"text","editOnDblClick":false},"editorMode":"ace/mode/text"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"rmr: DEPRECATED: Please use 'rm -r' instead.\n18/03/14 09:31:49 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.\nDeleted taewan\n"}]},"apps":[],"jobName":"paragraph_1521019888065_241559716","id":"20180314-093128_432174582","dateCreated":"Mar 14, 2018 9:31:28 AM","dateStarted":"Mar 14, 2018 9:31:47 AM","dateFinished":"Mar 14, 2018 9:31:49 AM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"%sh\ncd /var/lib/zeppelin/workspace/taewan/linkage\nhadoop fs -mkdir taewan/\nhadoop fs -mkdir taewan/linkage\nhadoop fs -ls taewan/linkage","user":"anonymous","dateUpdated":"Mar 14, 2018 9:32:22 AM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"sh","editOnDblClick":"false"},"editorMode":"ace/mode/sh","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1521016061006_1738764947","id":"20180314-082741_1879500511","dateCreated":"Mar 14, 2018 8:27:41 AM","dateStarted":"Mar 14, 2018 9:32:09 AM","dateFinished":"Mar 14, 2018 9:32:18 AM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"%sh\ncd /var/lib/zeppelin/workspace/taewan/linkage\nhadoop fs -put block_*.csv taewan/linkage","user":"anonymous","dateUpdated":"Mar 14, 2018 9:33:03 AM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"sh","editOnDblClick":"false"},"editorMode":"ace/mode/sh","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1521016133313_2115880689","id":"20180314-082853_2018348997","dateCreated":"Mar 14, 2018 8:28:53 AM","dateStarted":"Mar 14, 2018 9:32:50 AM","dateFinished":"Mar 14, 2018 9:32:54 AM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"%sh\nhadoop fs -ls taewan/linkage","user":"anonymous","dateUpdated":"Mar 14, 2018 9:33:06 AM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"sh","editOnDblClick":"false"},"editorMode":"ace/mode/sh","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Found 10 items\n-rw-r--r--   2 zeppelin hdfs   26248574 2018-03-14 09:32 taewan/linkage/block_1.csv\n-rw-r--r--   2 zeppelin hdfs   26255957 2018-03-14 09:32 taewan/linkage/block_10.csv\n-rw-r--r--   2 zeppelin hdfs   26241784 2018-03-14 09:32 taewan/linkage/block_2.csv\n-rw-r--r--   2 zeppelin hdfs   26253247 2018-03-14 09:32 taewan/linkage/block_3.csv\n-rw-r--r--   2 zeppelin hdfs   26247471 2018-03-14 09:32 taewan/linkage/block_4.csv\n-rw-r--r--   2 zeppelin hdfs   26249424 2018-03-14 09:32 taewan/linkage/block_5.csv\n-rw-r--r--   2 zeppelin hdfs   26256126 2018-03-14 09:32 taewan/linkage/block_6.csv\n-rw-r--r--   2 zeppelin hdfs   26261911 2018-03-14 09:32 taewan/linkage/block_7.csv\n-rw-r--r--   2 zeppelin hdfs   26253911 2018-03-14 09:32 taewan/linkage/block_8.csv\n-rw-r--r--   2 zeppelin hdfs   26254012 2018-03-14 09:32 taewan/linkage/block_9.csv\n"}]},"apps":[],"jobName":"paragraph_1521016200867_-1932939256","id":"20180314-083000_1455690924","dateCreated":"Mar 14, 2018 8:30:00 AM","dateStarted":"Mar 14, 2018 9:33:06 AM","dateFinished":"Mar 14, 2018 9:33:09 AM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"%md\n## Loding Demo-Data\n","user":"anonymous","dateUpdated":"Mar 14, 2018 8:44:15 AM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"text","editOnDblClick":false},"editorMode":"ace/mode/text","editorHide":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>Loding Demo-Data</h2>\n</div>"}]},"apps":[],"jobName":"paragraph_1521017020590_74290823","id":"20180314-084340_1684022381","dateCreated":"Mar 14, 2018 8:43:40 AM","dateStarted":"Mar 14, 2018 8:44:12 AM","dateFinished":"Mar 14, 2018 8:44:12 AM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"val rawblocks = sc.textFile(\"taewan/linkage\")\nrawblocks.count()\n","user":"anonymous","dateUpdated":"Mar 15, 2018 12:54:24 AM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nrawblocks: org.apache.spark.rdd.RDD[String] = taewan/linkage MapPartitionsRDD[1159] at textFile at <console>:49\n\nres205: Long = 5749142\n"}]},"apps":[],"jobName":"paragraph_1521016451433_-1032659122","id":"20180314-083411_1879468628","dateCreated":"Mar 14, 2018 8:34:11 AM","dateStarted":"Mar 15, 2018 12:54:24 AM","dateFinished":"Mar 15, 2018 12:54:25 AM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"//partition 갯수\nval partitions = rawblocks.partitions\npartitions.length","user":"anonymous","dateUpdated":"Mar 15, 2018 12:54:28 AM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\npartitions: Array[org.apache.spark.Partition] = Array(org.apache.spark.rdd.HadoopPartition@8ffb, org.apache.spark.rdd.HadoopPartition@8ffc, org.apache.spark.rdd.HadoopPartition@8ffd, org.apache.spark.rdd.HadoopPartition@8ffe, org.apache.spark.rdd.HadoopPartition@8fff, org.apache.spark.rdd.HadoopPartition@9000, org.apache.spark.rdd.HadoopPartition@9001, org.apache.spark.rdd.HadoopPartition@9002, org.apache.spark.rdd.HadoopPartition@9003, org.apache.spark.rdd.HadoopPartition@9004)\n\nres207: Int = 10\n"}]},"apps":[],"jobName":"paragraph_1521028261693_277571381","id":"20180314-115101_1198622072","dateCreated":"Mar 14, 2018 11:51:01 AM","dateStarted":"Mar 15, 2018 12:54:29 AM","dateFinished":"Mar 15, 2018 12:54:29 AM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"%md\n- rdd 첫번째 데이터 조회","user":"anonymous","dateUpdated":"Mar 15, 2018 12:54:32 AM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"text","editOnDblClick":false},"editorMode":"ace/mode/text","editorHide":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<ul>\n  <li>rdd 첫번째 데이터 조회</li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1521020004738_1954262605","id":"20180314-093324_1313591006","dateCreated":"Mar 14, 2018 9:33:24 AM","dateStarted":"Mar 15, 2018 12:54:32 AM","dateFinished":"Mar 15, 2018 12:54:32 AM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"rawblocks.first","user":"anonymous","dateUpdated":"Mar 15, 2018 12:54:36 AM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nres208: String = \"id_1\",\"id_2\",\"cmp_fname_c1\",\"cmp_fname_c2\",\"cmp_lname_c1\",\"cmp_lname_c2\",\"cmp_sex\",\"cmp_bd\",\"cmp_bm\",\"cmp_by\",\"cmp_plz\",\"is_match\"\n"}]},"apps":[],"jobName":"paragraph_1521016887834_2034419547","id":"20180314-084127_687713561","dateCreated":"Mar 14, 2018 8:41:27 AM","dateStarted":"Mar 15, 2018 12:54:36 AM","dateFinished":"Mar 15, 2018 12:54:36 AM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"%md\n- 10줄 가져오기\n    - 10줄 데이터 로절에 가져오기 \n    - Zeppline이 구동중인 서버\n    - rdd.take는 지정된 데이터를 로컬로 가져오는 것\n    - rdd.collect는 모든 데이터를 로컬로 가져오는 것","user":"anonymous","dateUpdated":"Mar 14, 2018 9:40:49 AM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala","editorHide":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<ul>\n  <li>10줄 가져오기\n    <ul>\n      <li>10줄 데이터 로절에 가져오기</li>\n      <li>Zeppline이 구동중인 서버</li>\n      <li>rdd.take는 지정된 데이터를 로컬로 가져오는 것</li>\n      <li>rdd.collect는 모든 데이터를 로컬로 가져오는 것</li>\n    </ul>\n  </li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1521020040788_-2034783343","id":"20180314-093400_1598478517","dateCreated":"Mar 14, 2018 9:34:00 AM","dateStarted":"Mar 14, 2018 9:40:47 AM","dateFinished":"Mar 14, 2018 9:40:47 AM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"val head = rawblocks.take(10)","user":"anonymous","dateUpdated":"Mar 15, 2018 12:54:39 AM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nhead: Array[String] = Array(\"id_1\",\"id_2\",\"cmp_fname_c1\",\"cmp_fname_c2\",\"cmp_lname_c1\",\"cmp_lname_c2\",\"cmp_sex\",\"cmp_bd\",\"cmp_bm\",\"cmp_by\",\"cmp_plz\",\"is_match\", 37291,53113,0.833333333333333,?,1,?,1,1,1,1,0,TRUE, 39086,47614,1,?,1,?,1,1,1,1,1,TRUE, 70031,70237,1,?,1,?,1,1,1,1,1,TRUE, 84795,97439,1,?,1,?,1,1,1,1,1,TRUE, 36950,42116,1,?,1,1,1,1,1,1,1,TRUE, 42413,48491,1,?,1,?,1,1,1,1,1,TRUE, 25965,64753,1,?,1,?,1,1,1,1,1,TRUE, 49451,90407,1,?,1,?,1,1,1,1,0,TRUE, 39932,40902,1,?,1,?,1,1,1,1,1,TRUE)\n"}]},"apps":[],"jobName":"paragraph_1521016912026_449436324","id":"20180314-084152_826747111","dateCreated":"Mar 14, 2018 8:41:52 AM","dateStarted":"Mar 15, 2018 12:54:39 AM","dateFinished":"Mar 15, 2018 12:54:39 AM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"//head 배열 사이즈 \nhead.length","user":"anonymous","dateUpdated":"Mar 15, 2018 12:54:42 AM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nres210: Int = 10\n"}]},"apps":[],"jobName":"paragraph_1521016930161_-2136060960","id":"20180314-084210_1029267380","dateCreated":"Mar 14, 2018 8:42:10 AM","dateStarted":"Mar 15, 2018 12:54:42 AM","dateFinished":"Mar 15, 2018 12:54:42 AM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"%md\n- higher-order function 사용","user":"anonymous","dateUpdated":"Mar 14, 2018 12:06:46 PM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":"true"},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<ul>\n  <li>higher-order function 사용</li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1521028677609_1762516601","id":"20180314-115757_977821013","dateCreated":"Mar 14, 2018 11:57:57 AM","dateStarted":"Mar 14, 2018 12:06:46 PM","dateFinished":"Mar 14, 2018 12:06:46 PM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"head.foreach((v:String)=>println(v))","user":"anonymous","dateUpdated":"Mar 15, 2018 12:54:45 AM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\"id_1\",\"id_2\",\"cmp_fname_c1\",\"cmp_fname_c2\",\"cmp_lname_c1\",\"cmp_lname_c2\",\"cmp_sex\",\"cmp_bd\",\"cmp_bm\",\"cmp_by\",\"cmp_plz\",\"is_match\"\n37291,53113,0.833333333333333,?,1,?,1,1,1,1,0,TRUE\n39086,47614,1,?,1,?,1,1,1,1,1,TRUE\n70031,70237,1,?,1,?,1,1,1,1,1,TRUE\n84795,97439,1,?,1,?,1,1,1,1,1,TRUE\n36950,42116,1,?,1,1,1,1,1,1,1,TRUE\n42413,48491,1,?,1,?,1,1,1,1,1,TRUE\n25965,64753,1,?,1,?,1,1,1,1,1,TRUE\n49451,90407,1,?,1,?,1,1,1,1,0,TRUE\n39932,40902,1,?,1,?,1,1,1,1,1,TRUE\n"}]},"apps":[],"jobName":"paragraph_1521028462080_245696875","id":"20180314-115422_1799536774","dateCreated":"Mar 14, 2018 11:54:22 AM","dateStarted":"Mar 15, 2018 12:54:45 AM","dateFinished":"Mar 15, 2018 12:54:45 AM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"//type은 생략 가능\nhead.foreach(v=>println(v))","user":"anonymous","dateUpdated":"Mar 15, 2018 12:54:48 AM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\"id_1\",\"id_2\",\"cmp_fname_c1\",\"cmp_fname_c2\",\"cmp_lname_c1\",\"cmp_lname_c2\",\"cmp_sex\",\"cmp_bd\",\"cmp_bm\",\"cmp_by\",\"cmp_plz\",\"is_match\"\n37291,53113,0.833333333333333,?,1,?,1,1,1,1,0,TRUE\n39086,47614,1,?,1,?,1,1,1,1,1,TRUE\n70031,70237,1,?,1,?,1,1,1,1,1,TRUE\n84795,97439,1,?,1,?,1,1,1,1,1,TRUE\n36950,42116,1,?,1,1,1,1,1,1,1,TRUE\n42413,48491,1,?,1,?,1,1,1,1,1,TRUE\n25965,64753,1,?,1,?,1,1,1,1,1,TRUE\n49451,90407,1,?,1,?,1,1,1,1,0,TRUE\n39932,40902,1,?,1,?,1,1,1,1,1,TRUE\n"}]},"apps":[],"jobName":"paragraph_1521028574271_543293309","id":"20180314-115614_1914839805","dateCreated":"Mar 14, 2018 11:56:14 AM","dateStarted":"Mar 15, 2018 12:54:48 AM","dateFinished":"Mar 15, 2018 12:54:48 AM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"//input 1개 println의 파라미터 1개 추론 가능\nhead.foreach(println)","user":"anonymous","dateUpdated":"Mar 15, 2018 12:54:50 AM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\"id_1\",\"id_2\",\"cmp_fname_c1\",\"cmp_fname_c2\",\"cmp_lname_c1\",\"cmp_lname_c2\",\"cmp_sex\",\"cmp_bd\",\"cmp_bm\",\"cmp_by\",\"cmp_plz\",\"is_match\"\n37291,53113,0.833333333333333,?,1,?,1,1,1,1,0,TRUE\n39086,47614,1,?,1,?,1,1,1,1,1,TRUE\n70031,70237,1,?,1,?,1,1,1,1,1,TRUE\n84795,97439,1,?,1,?,1,1,1,1,1,TRUE\n36950,42116,1,?,1,1,1,1,1,1,1,TRUE\n42413,48491,1,?,1,?,1,1,1,1,1,TRUE\n25965,64753,1,?,1,?,1,1,1,1,1,TRUE\n49451,90407,1,?,1,?,1,1,1,1,0,TRUE\n39932,40902,1,?,1,?,1,1,1,1,1,TRUE\n"}]},"apps":[],"jobName":"paragraph_1521028604874_360968303","id":"20180314-115644_2072402883","dateCreated":"Mar 14, 2018 11:56:44 AM","dateStarted":"Mar 15, 2018 12:54:50 AM","dateFinished":"Mar 15, 2018 12:54:50 AM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"%md\n### RDD 데이터 하둡에 저장","user":"anonymous","dateUpdated":"Mar 14, 2018 9:42:02 AM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"text","editOnDblClick":false},"editorMode":"ace/mode/text","editorHide":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>RDD 데이터 하둡에 저장</h3>\n</div>"}]},"apps":[],"jobName":"paragraph_1521020491291_-1878360228","id":"20180314-094131_733013449","dateCreated":"Mar 14, 2018 9:41:31 AM","dateStarted":"Mar 14, 2018 9:41:59 AM","dateFinished":"Mar 14, 2018 9:41:59 AM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"%md\n- rawblocks 데이터 저장","user":"anonymous","dateUpdated":"Mar 14, 2018 11:28:46 AM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala","editorHide":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<ul>\n  <li>rawblocks 데이터 저장</li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1521026904788_-1195606442","id":"20180314-112824_1454418339","dateCreated":"Mar 14, 2018 11:28:24 AM","dateStarted":"Mar 14, 2018 11:28:44 AM","dateFinished":"Mar 14, 2018 11:28:44 AM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"%sh\nhadoop fs -rmr taewan/temp_linkage","user":"anonymous","dateUpdated":"Mar 15, 2018 12:56:55 AM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"sh","editOnDblClick":"false"},"editorMode":"ace/mode/sh","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"rmr: DEPRECATED: Please use 'rm -r' instead.\nrmr: `taewan/temp_linkage': No such file or directory\n"},{"type":"TEXT","data":"ExitValue: 1"}]},"apps":[],"jobName":"paragraph_1521075368644_483903914","id":"20180315-005608_33521380","dateCreated":"Mar 15, 2018 12:56:08 AM","dateStarted":"Mar 15, 2018 12:56:48 AM","dateFinished":"Mar 15, 2018 12:56:50 AM","status":"ERROR","progressUpdateIntervalMs":500},{"text":"rawblocks.saveAsTextFile(\"taewan/temp_linkage\")","user":"anonymous","dateUpdated":"Mar 15, 2018 12:57:08 AM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala","editorHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1521016948624_-984076781","id":"20180314-084228_774188633","dateCreated":"Mar 14, 2018 8:42:28 AM","dateStarted":"Mar 15, 2018 12:57:00 AM","dateFinished":"Mar 15, 2018 12:57:01 AM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"%md\n- HDFS 저장 목록 조회","user":"anonymous","dateUpdated":"Mar 14, 2018 11:29:26 AM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":"true"},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<ul>\n  <li>HDFS 저장 목록 조회</li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1521026940238_-1396198537","id":"20180314-112900_267608478","dateCreated":"Mar 14, 2018 11:29:00 AM","dateStarted":"Mar 14, 2018 11:29:26 AM","dateFinished":"Mar 14, 2018 11:29:26 AM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"%sh\nhadoop fs -lsr taewan/temp_linkage","user":"anonymous","dateUpdated":"Mar 15, 2018 12:57:05 AM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"sh","editOnDblClick":"false"},"editorMode":"ace/mode/sh","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"lsr: DEPRECATED: Please use 'ls -R' instead.\n-rw-r--r--   2 zeppelin hdfs          0 2018-03-15 00:57 taewan/temp_linkage/_SUCCESS\n-rw-r--r--   2 zeppelin hdfs   26248574 2018-03-15 00:57 taewan/temp_linkage/part-00000\n-rw-r--r--   2 zeppelin hdfs   26255957 2018-03-15 00:57 taewan/temp_linkage/part-00001\n-rw-r--r--   2 zeppelin hdfs   26241784 2018-03-15 00:57 taewan/temp_linkage/part-00002\n-rw-r--r--   2 zeppelin hdfs   26253247 2018-03-15 00:57 taewan/temp_linkage/part-00003\n-rw-r--r--   2 zeppelin hdfs   26247471 2018-03-15 00:57 taewan/temp_linkage/part-00004\n-rw-r--r--   2 zeppelin hdfs   26249424 2018-03-15 00:57 taewan/temp_linkage/part-00005\n-rw-r--r--   2 zeppelin hdfs   26256126 2018-03-15 00:57 taewan/temp_linkage/part-00006\n-rw-r--r--   2 zeppelin hdfs   26261911 2018-03-15 00:57 taewan/temp_linkage/part-00007\n-rw-r--r--   2 zeppelin hdfs   26253911 2018-03-15 00:57 taewan/temp_linkage/part-00008\n-rw-r--r--   2 zeppelin hdfs   26254012 2018-03-15 00:57 taewan/temp_linkage/part-00009\n"}]},"apps":[],"jobName":"paragraph_1521020155290_-623003356","id":"20180314-093555_1714087916","dateCreated":"Mar 14, 2018 9:35:55 AM","dateStarted":"Mar 15, 2018 12:57:05 AM","dateFinished":"Mar 15, 2018 12:57:08 AM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"%sh\nhadoop fs -count taewan/temp_linkage","user":"anonymous","dateUpdated":"Mar 15, 2018 12:57:13 AM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"sh","editOnDblClick":"false"},"editorMode":"ace/mode/sh","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"           1           11          262522417 taewan/temp_linkage\n"}]},"apps":[],"jobName":"paragraph_1521020655643_1997629196","id":"20180314-094415_1510765652","dateCreated":"Mar 14, 2018 9:44:15 AM","dateStarted":"Mar 15, 2018 12:57:13 AM","dateFinished":"Mar 15, 2018 12:57:16 AM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"%md\n### header 라인 제거","user":"anonymous","dateUpdated":"Mar 14, 2018 12:08:13 PM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"text","editOnDblClick":false},"editorMode":"ace/mode/text","editorHide":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>header 라인 제거</h3>\n</div>"}]},"apps":[],"jobName":"paragraph_1521026904591_-1229079597","id":"20180314-112824_89629662","dateCreated":"Mar 14, 2018 11:28:24 AM","dateStarted":"Mar 14, 2018 12:08:10 PM","dateFinished":"Mar 14, 2018 12:08:10 PM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"rawblocks.first","user":"anonymous","dateUpdated":"Mar 15, 2018 12:57:22 AM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":"false"},"editorMode":"ace/mode/scala","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nres219: String = \"id_1\",\"id_2\",\"cmp_fname_c1\",\"cmp_fname_c2\",\"cmp_lname_c1\",\"cmp_lname_c2\",\"cmp_sex\",\"cmp_bd\",\"cmp_bm\",\"cmp_by\",\"cmp_plz\",\"is_match\"\n"}]},"apps":[],"jobName":"paragraph_1521020841407_1793002433","id":"20180314-094721_144696181","dateCreated":"Mar 14, 2018 9:47:21 AM","dateStarted":"Mar 15, 2018 12:57:20 AM","dateFinished":"Mar 15, 2018 12:57:20 AM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"%md\n- 첫번째 라이는 csv의 header 라인\n- 실제 데이터가 아니기에 제거해야 함","user":"anonymous","dateUpdated":"Mar 14, 2018 12:09:13 PM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":"true"},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<ul>\n  <li>첫번째 라이는 csv의 header 라인</li>\n  <li>실제 데이터가 아니기에 제거해야 함</li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1521029322994_877868845","id":"20180314-120842_1641792984","dateCreated":"Mar 14, 2018 12:08:42 PM","dateStarted":"Mar 14, 2018 12:09:13 PM","dateFinished":"Mar 14, 2018 12:09:13 PM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"//header라인 판별 함수 정의\ndef isHeader(line:String) = line.contains(\"id_1\")","user":"anonymous","dateUpdated":"Mar 15, 2018 12:57:27 AM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nisHeader: (line: String)Boolean\n"}]},"apps":[],"jobName":"paragraph_1521029352654_-1922856316","id":"20180314-120912_646221469","dateCreated":"Mar 14, 2018 12:09:12 PM","dateStarted":"Mar 15, 2018 12:57:28 AM","dateFinished":"Mar 15, 2018 12:57:28 AM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"%md\n- 동일 의미 함수\n    - 반환형을 지정\n\n```scala\ndef isHeader(line:String):String{\n    line.contains(\"id_1\")\n}\n```","user":"anonymous","dateUpdated":"Mar 14, 2018 12:11:51 PM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":"true"},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<ul>\n  <li>동일 의미 함수\n    <ul>\n      <li>반환형을 지정</li>\n    </ul>\n  </li>\n</ul>\n<pre><code class=\"scala\">def isHeader(line:String):String{\n    line.contains(&quot;id_1&quot;)\n}\n</code></pre>\n</div>"}]},"apps":[],"jobName":"paragraph_1521029413461_-779305964","id":"20180314-121013_1584131644","dateCreated":"Mar 14, 2018 12:10:13 PM","dateStarted":"Mar 14, 2018 12:11:51 PM","dateFinished":"Mar 14, 2018 12:11:51 PM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"%md\n- collection의 filter 함수에 isHeader 함수 적용하여 header 제거\n- 테스트에 haed 컬렉션 사용","user":"anonymous","dateUpdated":"Mar 14, 2018 12:12:46 PM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala","editorHide":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<ul>\n  <li>collection의 filter 함수에 isHeader 함수 적용하여 header 제거</li>\n  <li>테스트에 haed 컬렉션 사용</li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1521029488607_-1405217448","id":"20180314-121128_1888502109","dateCreated":"Mar 14, 2018 12:11:28 PM","dateStarted":"Mar 14, 2018 12:12:43 PM","dateFinished":"Mar 14, 2018 12:12:43 PM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"head.foreach(println)\n","user":"anonymous","dateUpdated":"Mar 15, 2018 12:57:32 AM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\"id_1\",\"id_2\",\"cmp_fname_c1\",\"cmp_fname_c2\",\"cmp_lname_c1\",\"cmp_lname_c2\",\"cmp_sex\",\"cmp_bd\",\"cmp_bm\",\"cmp_by\",\"cmp_plz\",\"is_match\"\n37291,53113,0.833333333333333,?,1,?,1,1,1,1,0,TRUE\n39086,47614,1,?,1,?,1,1,1,1,1,TRUE\n70031,70237,1,?,1,?,1,1,1,1,1,TRUE\n84795,97439,1,?,1,?,1,1,1,1,1,TRUE\n36950,42116,1,?,1,1,1,1,1,1,1,TRUE\n42413,48491,1,?,1,?,1,1,1,1,1,TRUE\n25965,64753,1,?,1,?,1,1,1,1,1,TRUE\n49451,90407,1,?,1,?,1,1,1,1,0,TRUE\n39932,40902,1,?,1,?,1,1,1,1,1,TRUE\n"}]},"apps":[],"jobName":"paragraph_1521029563645_-1952391681","id":"20180314-121243_464157790","dateCreated":"Mar 14, 2018 12:12:43 PM","dateStarted":"Mar 15, 2018 12:57:32 AM","dateFinished":"Mar 15, 2018 12:57:32 AM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"//filter=> 함수 결과가 true인 행 반환\nhead.filter(isHeader).foreach(println)","user":"anonymous","dateUpdated":"Mar 15, 2018 12:57:34 AM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\"id_1\",\"id_2\",\"cmp_fname_c1\",\"cmp_fname_c2\",\"cmp_lname_c1\",\"cmp_lname_c2\",\"cmp_sex\",\"cmp_bd\",\"cmp_bm\",\"cmp_by\",\"cmp_plz\",\"is_match\"\n"}]},"apps":[],"jobName":"paragraph_1521029576744_1919736574","id":"20180314-121256_888044457","dateCreated":"Mar 14, 2018 12:12:56 PM","dateStarted":"Mar 15, 2018 12:57:35 AM","dateFinished":"Mar 15, 2018 12:57:35 AM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"////filterNot=> 함수 결과가 false인 행 반환\nhead.filterNot(isHeader).foreach(println)","user":"anonymous","dateUpdated":"Mar 15, 2018 12:57:38 AM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"37291,53113,0.833333333333333,?,1,?,1,1,1,1,0,TRUE\n39086,47614,1,?,1,?,1,1,1,1,1,TRUE\n70031,70237,1,?,1,?,1,1,1,1,1,TRUE\n84795,97439,1,?,1,?,1,1,1,1,1,TRUE\n36950,42116,1,?,1,1,1,1,1,1,1,TRUE\n42413,48491,1,?,1,?,1,1,1,1,1,TRUE\n25965,64753,1,?,1,?,1,1,1,1,1,TRUE\n49451,90407,1,?,1,?,1,1,1,1,0,TRUE\n39932,40902,1,?,1,?,1,1,1,1,1,TRUE\n"}]},"apps":[],"jobName":"paragraph_1521029647565_573038803","id":"20180314-121407_1880702339","dateCreated":"Mar 14, 2018 12:14:07 PM","dateStarted":"Mar 15, 2018 12:57:38 AM","dateFinished":"Mar 15, 2018 12:57:39 AM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"//익명함수 사용시 not 연산자 사용 가능\n//head 타입이 Array[String]이기에 x의 타입은 String으로 유추\nhead.filter(x => !isHeader(x)).foreach(println)","user":"anonymous","dateUpdated":"Mar 15, 2018 12:57:46 AM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"37291,53113,0.833333333333333,?,1,?,1,1,1,1,0,TRUE\n39086,47614,1,?,1,?,1,1,1,1,1,TRUE\n70031,70237,1,?,1,?,1,1,1,1,1,TRUE\n84795,97439,1,?,1,?,1,1,1,1,1,TRUE\n36950,42116,1,?,1,1,1,1,1,1,1,TRUE\n42413,48491,1,?,1,?,1,1,1,1,1,TRUE\n25965,64753,1,?,1,?,1,1,1,1,1,TRUE\n49451,90407,1,?,1,?,1,1,1,1,0,TRUE\n39932,40902,1,?,1,?,1,1,1,1,1,TRUE\n"}]},"apps":[],"jobName":"paragraph_1521029685296_464032271","id":"20180314-121445_189674410","dateCreated":"Mar 14, 2018 12:14:45 PM","dateStarted":"Mar 15, 2018 12:57:46 AM","dateFinished":"Mar 15, 2018 12:57:46 AM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"//익명함수 표현 줄이기\n//_ 표기로 x=> 표기 줄임\nhead.filter(!isHeader(_)).foreach(println)","user":"anonymous","dateUpdated":"Mar 15, 2018 12:57:49 AM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"37291,53113,0.833333333333333,?,1,?,1,1,1,1,0,TRUE\n39086,47614,1,?,1,?,1,1,1,1,1,TRUE\n70031,70237,1,?,1,?,1,1,1,1,1,TRUE\n84795,97439,1,?,1,?,1,1,1,1,1,TRUE\n36950,42116,1,?,1,1,1,1,1,1,1,TRUE\n42413,48491,1,?,1,?,1,1,1,1,1,TRUE\n25965,64753,1,?,1,?,1,1,1,1,1,TRUE\n49451,90407,1,?,1,?,1,1,1,1,0,TRUE\n39932,40902,1,?,1,?,1,1,1,1,1,TRUE\n"}]},"apps":[],"jobName":"paragraph_1521029995761_1226445892","id":"20180314-121955_698432216","dateCreated":"Mar 14, 2018 12:19:55 PM","dateStarted":"Mar 15, 2018 12:57:49 AM","dateFinished":"Mar 15, 2018 12:57:50 AM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"%md\n## 클러스터에 코드 실행","user":"anonymous","dateUpdated":"Mar 14, 2018 2:13:33 PM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"text","editOnDblClick":false},"editorMode":"ace/mode/text","editorHide":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>클러스터에 코드 실행</h2>\n</div>"}]},"apps":[],"jobName":"paragraph_1521030378618_498235528","id":"20180314-122618_760550812","dateCreated":"Mar 14, 2018 12:26:18 PM","dateStarted":"Mar 14, 2018 2:13:30 PM","dateFinished":"Mar 14, 2018 2:13:30 PM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"%md\n- Error가 발생하는 이유? ","user":"anonymous","dateUpdated":"Mar 14, 2018 3:16:43 PM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala","editorHide":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<ul>\n  <li>Error가 발생하는 이유?</li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1521040589090_-1682629931","id":"20180314-151629_1985517168","dateCreated":"Mar 14, 2018 3:16:29 PM","dateStarted":"Mar 14, 2018 3:16:41 PM","dateFinished":"Mar 14, 2018 3:16:41 PM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"def isHeader(line:String):Boolean={\n    return line.contains(\"id_1\")\n}\nval noheader = rawblocks.filter(x => !isHeader(x) )\nnoheader.count()","user":"anonymous","dateUpdated":"Mar 15, 2018 12:57:57 AM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"\nisHeader: (line: String)Boolean\n\nnoheader: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[1163] at filter at <console>:53\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\norg.apache.spark.SparkException: Job aborted due to stage failure: Task 5 in stage 2077.0 failed 4 times, most recent failure: Lost task 5.3 in stage 2077.0 (TID 25284, bdc-demo-bdcsce-1.compute-gse00000548.oraclecloud.internal, executor 3): java.lang.NoClassDefFoundError: L$line18798334691/$read;\n\tat java.lang.Class.getDeclaredFields0(Native Method)\n\tat java.lang.Class.privateGetDeclaredFields(Class.java:2583)\n\tat java.lang.Class.getDeclaredField(Class.java:2068)\n\tat java.io.ObjectStreamClass.getDeclaredSUID(ObjectStreamClass.java:1803)\n\tat java.io.ObjectStreamClass.access$700(ObjectStreamClass.java:79)\n\tat java.io.ObjectStreamClass$2.run(ObjectStreamClass.java:494)\n\tat java.io.ObjectStreamClass$2.run(ObjectStreamClass.java:482)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat java.io.ObjectStreamClass.<init>(ObjectStreamClass.java:482)\n\tat java.io.ObjectStreamClass.lookup(ObjectStreamClass.java:379)\n\tat java.io.ObjectStreamClass.initNonProxy(ObjectStreamClass.java:669)\n\tat java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1880)\n\tat java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1746)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2037)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2282)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2206)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2282)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2206)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2282)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2206)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2282)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2206)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2282)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2206)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2282)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2206)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2282)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2206)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n\tat java.io.ObjectInputStream.readObject(ObjectInputStream.java:428)\n\tat org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:75)\n\tat org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:114)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:80)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:99)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.lang.ClassNotFoundException: $line18798334691.$read\n\tat org.apache.spark.repl.ExecutorClassLoader.findClass(ExecutorClassLoader.scala:82)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:424)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:357)\n\t... 52 more\nCaused by: java.lang.ClassNotFoundException: $line18798334691.$read\n\tat java.lang.ClassLoader.findClass(ClassLoader.java:530)\n\tat org.apache.spark.util.ParentClassLoader.findClass(ParentClassLoader.scala:26)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:424)\n\tat org.apache.spark.util.ParentClassLoader.loadClass(ParentClassLoader.scala:34)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:357)\n\tat org.apache.spark.util.ParentClassLoader.loadClass(ParentClassLoader.scala:30)\n\tat org.apache.spark.repl.ExecutorClassLoader.findClass(ExecutorClassLoader.scala:77)\n\t... 54 more\n\nDriver stacktrace:\n  at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435)\n  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423)\n  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422)\n  at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n  at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n  at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422)\n  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802)\n  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802)\n  at scala.Option.foreach(Option.scala:257)\n  at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802)\n  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1650)\n  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1605)\n  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1594)\n  at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n  at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:628)\n  at org.apache.spark.SparkContext.runJob(SparkContext.scala:1925)\n  at org.apache.spark.SparkContext.runJob(SparkContext.scala:1938)\n  at org.apache.spark.SparkContext.runJob(SparkContext.scala:1951)\n  at org.apache.spark.SparkContext.runJob(SparkContext.scala:1965)\n  at org.apache.spark.rdd.RDD.count(RDD.scala:1158)\n  ... 50 elided\nCaused by: java.lang.NoClassDefFoundError: L$line18798334691/$read;\n  at java.lang.Class.getDeclaredFields0(Native Method)\n  at java.lang.Class.privateGetDeclaredFields(Class.java:2583)\n  at java.lang.Class.getDeclaredField(Class.java:2068)\n  at java.io.ObjectStreamClass.getDeclaredSUID(ObjectStreamClass.java:1803)\n  at java.io.ObjectStreamClass.access$700(ObjectStreamClass.java:79)\n  at java.io.ObjectStreamClass$2.run(ObjectStreamClass.java:494)\n  at java.io.ObjectStreamClass$2.run(ObjectStreamClass.java:482)\n  at java.security.AccessController.doPrivileged(Native Method)\n  at java.io.ObjectStreamClass.<init>(ObjectStreamClass.java:482)\n  at java.io.ObjectStreamClass.lookup(ObjectStreamClass.java:379)\n  at java.io.ObjectStreamClass.initNonProxy(ObjectStreamClass.java:669)\n  at java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1880)\n  at java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1746)\n  at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2037)\n  at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n  at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2282)\n  at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2206)\n  at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n  at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n  at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2282)\n  at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2206)\n  a\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nt java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n  at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n  at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2282)\n  at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2206)\n  at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n  at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n  at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2282)\n  at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2206)\n  at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n  at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n  at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2282)\n  at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2206)\n  at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n  at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n  at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2282)\n  at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2206)\n  at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n  at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n  at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2282)\n  at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2206)\n  at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n  at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n  at java.io.ObjectInputStream.readObject(ObjectInputStream.java:428)\n  at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:75)\n  at org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:114)\n  at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:80)\n  at org.apache.spark.scheduler.Task.run(Task.scala:99)\n  at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)\n  ... 3 more\nCaused by: java.lang.ClassNotFoundException: $line18798334691.$read\n  at org.apache.spark.repl.ExecutorClassLoader.findClass(ExecutorClassLoader.scala:82)\n  at java.lang.ClassLoader.loadClass(ClassLoader.java:424)\n  at java.lang.ClassLoader.loadClass(ClassLoader.java:357)\n  ... 52 more\nCaused by: java.lang.ClassNotFoundException: $line18798334691.$read\n  at java.lang.ClassLoader.findClass(ClassLoader.java:530)\n  at org.apache.spark.util.ParentClassLoader.findClass(ParentClassLoader.scala:26)\n  at java.lang.ClassLoader.loadClass(ClassLoader.java:424)\n  at org.apache.spark.util.ParentClassLoader.loadClass(ParentClassLoader.scala:34)\n  at java.lang.ClassLoader.loadClass(ClassLoader.java:357)\n  at org.apache.spark.util.ParentClassLoader.loadClass(ParentClassLoader.scala:30)\n  at org.apache.spark.repl.ExecutorClassLoader.findClass(ExecutorClassLoader.scala:77)\n  ... 54 more\n"}]},"apps":[],"jobName":"paragraph_1521036800677_1384306714","id":"20180314-141320_129959735","dateCreated":"Mar 14, 2018 2:13:20 PM","dateStarted":"Mar 15, 2018 12:57:57 AM","dateFinished":"Mar 15, 2018 12:57:57 AM","status":"ERROR","progressUpdateIntervalMs":500},{"text":"val noheader = rawblocks.filter(x => !x.contains(\"id_1\") )\nnoheader.count()\n","user":"anonymous","dateUpdated":"Mar 15, 2018 12:58:09 AM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nnoheader: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[1164] at filter at <console>:51\n\nres231: Long = 5749132\n"}]},"apps":[],"jobName":"paragraph_1521036867633_1917042734","id":"20180314-141427_2126584110","dateCreated":"Mar 14, 2018 2:14:27 PM","dateStarted":"Mar 15, 2018 12:58:09 AM","dateFinished":"Mar 15, 2018 12:58:10 AM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"noheader.first","user":"anonymous","dateUpdated":"Mar 15, 2018 12:58:14 AM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nres232: String = 37291,53113,0.833333333333333,?,1,?,1,1,1,1,0,TRUE\n"}]},"apps":[],"jobName":"paragraph_1521038795045_908990749","id":"20180314-144635_170208547","dateCreated":"Mar 14, 2018 2:46:35 PM","dateStarted":"Mar 15, 2018 12:58:15 AM","dateFinished":"Mar 15, 2018 12:58:15 AM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"%md\n## DataFrame\n\n- spark 1.3에서 도입\n- DataFrame은 열 집합으로 구성\n- 정형 구조로 RDD를 추상화\n- 관계형 데이터베이스의 테이블과 같은 구조를 \n- spark의 데이터프레임은 분산된 데이터 셋","user":"anonymous","dateUpdated":"Mar 14, 2018 4:19:30 PM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"text","editOnDblClick":false},"editorMode":"ace/mode/text","editorHide":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>DataFrame</h2>\n<ul>\n  <li>spark 1.3에서 도입</li>\n  <li>DataFrame은 열 집합으로 구성</li>\n  <li>정형 구조로 RDD를 추상화</li>\n  <li>관계형 데이터베이스의 테이블과 같은 구조를</li>\n  <li>spark의 데이터프레임은 분산된 데이터 셋</li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1521040644462_2105885220","id":"20180314-151724_1118007591","dateCreated":"Mar 14, 2018 3:17:24 PM","dateStarted":"Mar 14, 2018 4:19:28 PM","dateFinished":"Mar 14, 2018 4:19:28 PM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"//모든 컬럼을 string 타입으로 설정\nval prev = spark.read.csv(\"taewan/linkage\")\n","user":"anonymous","dateUpdated":"Mar 15, 2018 12:58:21 AM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nprev: org.apache.spark.sql.DataFrame = [_c0: string, _c1: string ... 10 more fields]\n"}]},"apps":[],"jobName":"paragraph_1521042469996_-1961106056","id":"20180314-154749_2099552963","dateCreated":"Mar 14, 2018 3:47:49 PM","dateStarted":"Mar 15, 2018 12:58:21 AM","dateFinished":"Mar 15, 2018 12:58:21 AM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"prev.show()","user":"anonymous","dateUpdated":"Mar 14, 2018 4:21:47 PM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-----+-----+------------+------------+------------+------------+-------+------+------+------+-------+--------+\n|  _c0|  _c1|         _c2|         _c3|         _c4|         _c5|    _c6|   _c7|   _c8|   _c9|   _c10|    _c11|\n+-----+-----+------------+------------+------------+------------+-------+------+------+------+-------+--------+\n| id_1| id_2|cmp_fname_c1|cmp_fname_c2|cmp_lname_c1|cmp_lname_c2|cmp_sex|cmp_bd|cmp_bm|cmp_by|cmp_plz|is_match|\n| 3148| 8326|           1|           ?|           1|           ?|      1|     1|     1|     1|      1|    TRUE|\n|14055|94934|           1|           ?|           1|           ?|      1|     1|     1|     1|      1|    TRUE|\n|33948|34740|           1|           ?|           1|           ?|      1|     1|     1|     1|      1|    TRUE|\n|  946|71870|           1|           ?|           1|           ?|      1|     1|     1|     1|      1|    TRUE|\n|64880|71676|           1|           ?|           1|           ?|      1|     1|     1|     1|      1|    TRUE|\n|25739|45991|           1|           ?|           1|           ?|      1|     1|     1|     1|      1|    TRUE|\n|62415|93584|           1|           ?|           1|           ?|      1|     1|     1|     1|      0|    TRUE|\n|27995|31399|           1|           ?|           1|           ?|      1|     1|     1|     1|      1|    TRUE|\n| 4909|12238|           1|           ?|           1|           ?|      1|     1|     1|     1|      1|    TRUE|\n|15161|16743|           1|           ?|           1|           ?|      1|     1|     1|     1|      1|    TRUE|\n|31703|37310|           1|           ?|           1|           ?|      1|     1|     1|     1|      1|    TRUE|\n|30213|36558|           1|           ?|           1|           ?|      1|     1|     1|     1|      1|    TRUE|\n|56596|56630|           1|           ?|           1|           ?|      1|     1|     1|     1|      1|    TRUE|\n|16481|21174|           1|           ?|           1|           ?|      1|     1|     1|     1|      1|    TRUE|\n|32649|37094|           1|           ?|           1|           ?|      1|     1|     1|     1|      1|    TRUE|\n|34268|37260|           1|           ?|           1|           ?|      1|     1|     1|     1|      1|    TRUE|\n|66117|69253|           1|           ?|           1|           ?|      1|     1|     1|     1|      0|    TRUE|\n| 2771|31982|           1|           ?|           1|           ?|      0|     1|     1|     1|      1|    TRUE|\n|23557|29673|           1|           ?|           1|           ?|      1|     1|     1|     1|      1|    TRUE|\n+-----+-----+------------+------------+------------+------------+-------+------+------+------+-------+--------+\nonly showing top 20 rows\n\n"}]},"apps":[],"jobName":"paragraph_1521044385883_-881169565","id":"20180314-161945_1693302628","dateCreated":"Mar 14, 2018 4:19:45 PM","dateStarted":"Mar 14, 2018 4:21:47 PM","dateFinished":"Mar 14, 2018 4:21:47 PM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"%md\n- 현재 문제 점\n    - 열 이름이 기본 값\n    - header가 첫번째 행\n    - ?로 누락된 값","user":"anonymous","dateUpdated":"Mar 14, 2018 4:23:12 PM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":"true"},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<ul>\n  <li>현재 문제 점\n    <ul>\n      <li>열 이름이 기본 값</li>\n      <li>header가 첫번째 행</li>\n      <li>?로 누락된 값</li>\n    </ul>\n  </li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1521044392906_-581050099","id":"20180314-161952_328298743","dateCreated":"Mar 14, 2018 4:19:52 PM","dateStarted":"Mar 14, 2018 4:23:12 PM","dateFinished":"Mar 14, 2018 4:23:12 PM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"%md\n- 추가 옵션 설정\n    - header\n    - nullValue\n    - inferSchema","user":"anonymous","dateUpdated":"Mar 14, 2018 4:24:15 PM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala","editorHide":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<ul>\n  <li>추가 옵션 설정\n    <ul>\n      <li>header</li>\n      <li>nullValue</li>\n      <li>inferSchema</li>\n    </ul>\n  </li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1521044592120_-2094395573","id":"20180314-162312_84635163","dateCreated":"Mar 14, 2018 4:23:12 PM","dateStarted":"Mar 14, 2018 4:24:14 PM","dateFinished":"Mar 14, 2018 4:24:14 PM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"val parsed = spark.read.option(\"header\", \"true\").\n            option(\"nullValue\", \"?\").\n            option(\"inferSchema\", \"true\").\n            csv(\"taewan/linkage\")\n","user":"anonymous","dateUpdated":"Mar 15, 2018 12:58:32 AM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nparsed: org.apache.spark.sql.DataFrame = [id_1: int, id_2: int ... 10 more fields]\n"}]},"apps":[],"jobName":"paragraph_1521044636572_-1984079908","id":"20180314-162356_1842570658","dateCreated":"Mar 14, 2018 4:23:56 PM","dateStarted":"Mar 15, 2018 12:58:32 AM","dateFinished":"Mar 15, 2018 12:58:36 AM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"%md\n- csv 파일을 두번 읽음\n    - 첫번째: 스키마 탐색\n    - 두번쨰: 실제 파싱","user":"anonymous","dateUpdated":"Mar 14, 2018 4:31:27 PM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":"true"},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<ul>\n  <li>csv 파일을 두번 읽음\n    <ul>\n      <li>첫번째: 스키마 탐색</li>\n      <li>두번쨰: 실제 파싱</li>\n    </ul>\n  </li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1521045027656_412255546","id":"20180314-163027_551203913","dateCreated":"Mar 14, 2018 4:30:27 PM","dateStarted":"Mar 14, 2018 4:31:27 PM","dateFinished":"Mar 14, 2018 4:31:27 PM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"//Schema 출력\nparsed.printSchema()","user":"anonymous","dateUpdated":"Mar 15, 2018 12:58:39 AM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"root\n |-- id_1: integer (nullable = true)\n |-- id_2: integer (nullable = true)\n |-- cmp_fname_c1: double (nullable = true)\n |-- cmp_fname_c2: double (nullable = true)\n |-- cmp_lname_c1: double (nullable = true)\n |-- cmp_lname_c2: double (nullable = true)\n |-- cmp_sex: integer (nullable = true)\n |-- cmp_bd: integer (nullable = true)\n |-- cmp_bm: integer (nullable = true)\n |-- cmp_by: integer (nullable = true)\n |-- cmp_plz: integer (nullable = true)\n |-- is_match: boolean (nullable = true)\n\n"}]},"apps":[],"jobName":"paragraph_1521044765157_-1572262312","id":"20180314-162605_1598201182","dateCreated":"Mar 14, 2018 4:26:05 PM","dateStarted":"Mar 15, 2018 12:58:39 AM","dateFinished":"Mar 15, 2018 12:58:39 AM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"parsed.show()","user":"anonymous","dateUpdated":"Mar 15, 2018 12:58:44 AM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-----+-----+------------+------------+------------+------------+-------+------+------+------+-------+--------+\n| id_1| id_2|cmp_fname_c1|cmp_fname_c2|cmp_lname_c1|cmp_lname_c2|cmp_sex|cmp_bd|cmp_bm|cmp_by|cmp_plz|is_match|\n+-----+-----+------------+------------+------------+------------+-------+------+------+------+-------+--------+\n| 3148| 8326|         1.0|        null|         1.0|        null|      1|     1|     1|     1|      1|    true|\n|14055|94934|         1.0|        null|         1.0|        null|      1|     1|     1|     1|      1|    true|\n|33948|34740|         1.0|        null|         1.0|        null|      1|     1|     1|     1|      1|    true|\n|  946|71870|         1.0|        null|         1.0|        null|      1|     1|     1|     1|      1|    true|\n|64880|71676|         1.0|        null|         1.0|        null|      1|     1|     1|     1|      1|    true|\n|25739|45991|         1.0|        null|         1.0|        null|      1|     1|     1|     1|      1|    true|\n|62415|93584|         1.0|        null|         1.0|        null|      1|     1|     1|     1|      0|    true|\n|27995|31399|         1.0|        null|         1.0|        null|      1|     1|     1|     1|      1|    true|\n| 4909|12238|         1.0|        null|         1.0|        null|      1|     1|     1|     1|      1|    true|\n|15161|16743|         1.0|        null|         1.0|        null|      1|     1|     1|     1|      1|    true|\n|31703|37310|         1.0|        null|         1.0|        null|      1|     1|     1|     1|      1|    true|\n|30213|36558|         1.0|        null|         1.0|        null|      1|     1|     1|     1|      1|    true|\n|56596|56630|         1.0|        null|         1.0|        null|      1|     1|     1|     1|      1|    true|\n|16481|21174|         1.0|        null|         1.0|        null|      1|     1|     1|     1|      1|    true|\n|32649|37094|         1.0|        null|         1.0|        null|      1|     1|     1|     1|      1|    true|\n|34268|37260|         1.0|        null|         1.0|        null|      1|     1|     1|     1|      1|    true|\n|66117|69253|         1.0|        null|         1.0|        null|      1|     1|     1|     1|      0|    true|\n| 2771|31982|         1.0|        null|         1.0|        null|      0|     1|     1|     1|      1|    true|\n|23557|29673|         1.0|        null|         1.0|        null|      1|     1|     1|     1|      1|    true|\n|37156|39557|         1.0|        null|         1.0|        null|      1|     1|     1|     1|      1|    true|\n+-----+-----+------------+------------+------------+------------+-------+------+------+------+-------+--------+\nonly showing top 20 rows\n\n"}]},"apps":[],"jobName":"paragraph_1521044801166_1124904098","id":"20180314-162641_228777368","dateCreated":"Mar 14, 2018 4:26:41 PM","dateStarted":"Mar 15, 2018 12:58:44 AM","dateFinished":"Mar 15, 2018 12:58:44 AM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"%md\n- ```option(\"inferSchema\", \"true\")```옵션을 사용할 경우 데이터를 2번 읽음\n- 데이터가 큰 상황에서는 시간이 오래걸림\n- 스키마를 직접 설정 가능\n    - org.apache.spark.sql.types.StructType","user":"anonymous","dateUpdated":"Mar 15, 2018 12:55:22 AM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":"true"},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<ul>\n  <li><code>option(&quot;inferSchema&quot;, &quot;true&quot;)</code>옵션을 사용할 경우 데이터를 2번 읽음</li>\n  <li>데이터가 큰 상황에서는 시간이 오래걸림</li>\n  <li>스키마를 직접 설정 가능\n    <ul>\n      <li>org.apache.spark.sql.types.StructType</li>\n    </ul>\n  </li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1521044855525_1006663593","id":"20180314-162735_1318388507","dateCreated":"Mar 14, 2018 4:27:35 PM","dateStarted":"Mar 15, 2018 12:55:22 AM","dateFinished":"Mar 15, 2018 12:55:22 AM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"%md\n\n```scala\nval parsed = spark.read.option(\"header\", \"true\").\n            option(\"nullValue\", \"?\").\n            option(\"inferSchema\", \"true\").\n            csv(\"taewan/linkage\")\n```\n\n- csv(\"taewan/linkage\") 이외 다른 포멧 지원\n    - json\n    - parquet & orc => 열기반 바이너리 파일 포멧\n    - jdbc\n    - libsvm : 밀도가 낮은 데이터 포멧\n    - text\n    \n```\n//같은 의미\nval d1 = spark.read.format('json').load(\"file.json\")\nval d2 = spark.read.format('file.json')\n```","user":"anonymous","dateUpdated":"Mar 15, 2018 1:03:55 AM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala","editorHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<pre><code class=\"scala\">val parsed = spark.read.option(&quot;header&quot;, &quot;true&quot;).\n            option(&quot;nullValue&quot;, &quot;?&quot;).\n            option(&quot;inferSchema&quot;, &quot;true&quot;).\n            csv(&quot;taewan/linkage&quot;)\n</code></pre>\n<ul>\n  <li>csv(&ldquo;taewan/linkage&rdquo;) 이외 다른 포멧 지원\n    <ul>\n      <li>json</li>\n      <li>parquet &amp; orc =&gt; 열기반 바이너리 파일 포멧</li>\n      <li>jdbc</li>\n      <li>libsvm : 밀도가 낮은 데이터 포멧</li>\n      <li>text</li>\n    </ul>\n  </li>\n</ul>\n<pre><code>//같은 의미\nval d1 = spark.read.format(&#39;json&#39;).load(&quot;file.json&quot;)\nval d2 = spark.read.format(&#39;file.json&#39;)\n</code></pre>\n</div>"}]},"apps":[],"jobName":"paragraph_1521075322884_-1374646168","id":"20180315-005522_1922357127","dateCreated":"Mar 15, 2018 12:55:22 AM","dateStarted":"Mar 15, 2018 1:03:26 AM","dateFinished":"Mar 15, 2018 1:03:26 AM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"%md\n## DataFrame API로 데이터 분석하기","user":"anonymous","dateUpdated":"Mar 15, 2018 1:05:47 AM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala","editorHide":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>DataFrame API로 데이터 분석하기</h2>\n</div>"}]},"apps":[],"jobName":"paragraph_1521075611388_-596285463","id":"20180315-010011_1436165823","dateCreated":"Mar 15, 2018 1:00:11 AM","dateStarted":"Mar 15, 2018 1:05:44 AM","dateFinished":"Mar 15, 2018 1:05:44 AM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"%md\n- RDD 함수\n    - count\n    - countByValue: 히드토그램 \n    - stats: 통계값-최솟값, 최댓값, 평균, 표준편차\n    ","user":"anonymous","dateUpdated":"Mar 15, 2018 1:09:16 AM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala","editorHide":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<ul>\n  <li>RDD 함수\n    <ul>\n      <li>count</li>\n      <li>countByValue: 히드토그램</li>\n      <li>stats: 통계값-최솟값, 최댓값, 평균, 표준편차</li>\n    </ul>\n  </li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1521075943931_-603956894","id":"20180315-010543_1874468181","dateCreated":"Mar 15, 2018 1:05:43 AM","dateStarted":"Mar 15, 2018 1:09:14 AM","dateFinished":"Mar 15, 2018 1:09:14 AM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"%md\n- parsed 데이터 \n    - 첫번째 ~ 두번째 컬럼: 환자 ID\n    - 3th ~ 9th: 더블형, 정수형\n        - 각 필드의 매치 점수\n        - 정수형: (1, 매치됨), (0, 매치안됨)\n    - 마지막 필드: 매치 여부\n\n- 목표: 유사도에 따라서 레코드 일치 여부 측정 방법 고찰\n","user":"anonymous","dateUpdated":"Mar 15, 2018 1:13:18 AM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":"true"},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<ul>\n  <li>\n    <p>parsed 데이터</p>\n    <ul>\n      <li>첫번째 ~ 두번째 컬럼: 환자 ID</li>\n      <li>3th ~ 9th: 더블형, 정수형\n        <ul>\n          <li>각 필드의 매치 점수</li>\n          <li>정수형: (1, 매치됨), (0, 매치안됨)</li>\n        </ul>\n      </li>\n      <li>마지막 필드: 매치 여부</li>\n    </ul>\n  </li>\n  <li>\n  <p>목표: 유사도에 따라서 레코드 일치 여부 측정 방법 고찰</p></li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1521076101430_-637736532","id":"20180315-010821_464983644","dateCreated":"Mar 15, 2018 1:08:21 AM","dateStarted":"Mar 15, 2018 1:13:18 AM","dateFinished":"Mar 15, 2018 1:13:19 AM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"parsed.count()","user":"anonymous","dateUpdated":"Mar 15, 2018 1:13:29 AM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nres237: Long = 5749132\n"}]},"apps":[],"jobName":"paragraph_1521076351512_586102102","id":"20180315-011231_348814404","dateCreated":"Mar 15, 2018 1:12:31 AM","dateStarted":"Mar 15, 2018 1:13:30 AM","dateFinished":"Mar 15, 2018 1:13:32 AM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"%md\n\n- RDD를 저장하고 재작업을 방지하는 방법\n    - cache()\n\n```\ncached.cache()\ncached.count()\ncached.take(n)\n```","user":"anonymous","dateUpdated":"Mar 15, 2018 1:40:38 AM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":"true"},"editorMode":"ace/mode/markdown","editorHide":false,"tableHide":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<ul>\n  <li>RDD를 저장하고 재작업을 방지하는 방법\n    <ul>\n      <li>cache()</li>\n    </ul>\n  </li>\n</ul>\n<pre><code>cached.cache()\ncached.count()\ncached.take(n)\n</code></pre>\n</div>"}]},"apps":[],"jobName":"paragraph_1521076409923_-1388970533","id":"20180315-011329_821112664","dateCreated":"Mar 15, 2018 1:13:29 AM","dateStarted":"Mar 15, 2018 1:40:16 AM","dateFinished":"Mar 15, 2018 1:40:16 AM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"%md\n- persist(StorageLevel)\n- StorageLevel\n    - StorageLevel.MEMORY\n        - 원본 객체를 메모리에 로딩 \n    - StorageLevel.MEMORY_SER\n        - 직렬화된 객체를 메모리에 로딩 \n        - 20~50% 절감\n    - StorageLevel.MEMORY_AND_DISK\n        - 메모리 부족시 디스크 저장 \n    - StorageLevel.MEMORY_ADN_DISK_SER","user":"anonymous","dateUpdated":"Mar 15, 2018 5:49:53 AM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":"true"},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<ul>\n  <li>persist(StorageLevel)</li>\n  <li>StorageLevel\n    <ul>\n      <li>StorageLevel.MEMORY\n        <ul>\n          <li>원본 객체를 메모리에 로딩</li>\n        </ul>\n      </li>\n      <li>StorageLevel.MEMORY_SER\n        <ul>\n          <li>직렬화된 객체를 메모리에 로딩</li>\n          <li>20~50% 절감</li>\n        </ul>\n      </li>\n      <li>StorageLevel.MEMORY_AND_DISK\n        <ul>\n          <li>메모리 부족시 디스크 저장</li>\n        </ul>\n      </li>\n      <li>StorageLevel.MEMORY_ADN_DISK_SER</li>\n    </ul>\n  </li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1521077957401_1971284033","id":"20180315-013917_839539548","dateCreated":"Mar 15, 2018 1:39:17 AM","dateStarted":"Mar 15, 2018 5:49:53 AM","dateFinished":"Mar 15, 2018 5:49:53 AM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"//DataFrame에 저장된 데이터의 실제 타입\nparsed.rdd.first()","user":"anonymous","dateUpdated":"Mar 15, 2018 10:40:06 AM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala","editorHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nres294: org.apache.spark.sql.Row = [3148,8326,1.0,null,1.0,null,1,1,1,1,1,true]\n"}]},"apps":[],"jobName":"paragraph_1521092993307_1377171637","id":"20180315-054953_1971273666","dateCreated":"Mar 15, 2018 5:49:53 AM","dateStarted":"Mar 15, 2018 10:40:06 AM","dateFinished":"Mar 15, 2018 10:40:06 AM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"//지정한 컬럼의 값을 반환.\n//미지정 값에 대해서는 타입을 지정하여 해당 타입의 zero 상응 값으로 설정\n//countByValue() 값을 갖는 수\n//히스토그램 작성에 좋음\nparsed.rdd.map(_.getAs[Boolean](\"is_match\")).countByValue()\n","user":"anonymous","dateUpdated":"Mar 15, 2018 10:40:09 AM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nres296: scala.collection.Map[Boolean,Long] = Map(true -> 20931, false -> 5728201)\n"}]},"apps":[],"jobName":"paragraph_1521093112236_695750687","id":"20180315-055152_181391438","dateCreated":"Mar 15, 2018 5:51:52 AM","dateStarted":"Mar 15, 2018 10:40:09 AM","dateFinished":"Mar 15, 2018 10:40:16 AM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"%md\n- RDD에서 히스토그램용 데이터 분석\n    - countByValue & reduceByKey  효율적?\n    - 고유값이 작으면 countByValue가 좋음\n    - 고유값이 많으면 reduceByKey가 좋음\n- 일관적인 접근법: DataFrame이 제공","user":"anonymous","dateUpdated":"Mar 15, 2018 7:56:49 AM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":"true"},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<ul>\n  <li>RDD에서 히스토그램용 데이터 분석\n    <ul>\n      <li>countByValue &amp; reduceByKey 효율적?</li>\n      <li>고유값이 작으면 countByValue가 좋음</li>\n      <li>고유값이 많으면 reduceByKey가 좋음</li>\n    </ul>\n  </li>\n  <li>일관적인 접근법: DataFrame이 제공</li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1521100001211_1399463453","id":"20180315-074641_1716006100","dateCreated":"Mar 15, 2018 7:46:41 AM","dateStarted":"Mar 15, 2018 7:56:49 AM","dateFinished":"Mar 15, 2018 7:56:49 AM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"parsed.groupBy(\"is_match\").count().show()","user":"anonymous","dateUpdated":"Mar 15, 2018 10:40:30 AM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":"true"},"editorMode":"ace/mode/scala","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+--------+-------+\n|is_match|  count|\n+--------+-------+\n|    true|  20931|\n|   false|5728201|\n+--------+-------+\n\n"}]},"apps":[],"jobName":"paragraph_1521100609583_991503737","id":"20180315-075649_387239654","dateCreated":"Mar 15, 2018 7:56:49 AM","dateStarted":"Mar 15, 2018 10:40:23 AM","dateFinished":"Mar 15, 2018 10:40:27 AM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"parsed.groupBy(\"is_match\").count().orderBy($\"count\".desc).show()","user":"anonymous","dateUpdated":"Mar 15, 2018 10:40:36 AM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+--------+-------+\n|is_match|  count|\n+--------+-------+\n|   false|5728201|\n|    true|  20931|\n+--------+-------+\n\n"}]},"apps":[],"jobName":"paragraph_1521100660304_1852464506","id":"20180315-075740_2020008277","dateCreated":"Mar 15, 2018 7:57:40 AM","dateStarted":"Mar 15, 2018 10:40:36 AM","dateFinished":"Mar 15, 2018 10:40:40 AM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"%md\n- 사용 가능한 aggregation 함수 목록\n    - org.apache.spark.sql.functions\n    - https://spark.apache.org/docs/2.0.2/api/java/org/apache/spark/sql/functions.html\n    - function \n        - abs(Column e)\n        - stddev(Column e)\n        - count(Column e)\n        - variance(Column e)\n        - max(Column e)\n        - min(Column e)\n        - avg(Column e)\n    - ```$\"comunm_name\"```은 Column 객체로 변환","user":"anonymous","dateUpdated":"Mar 15, 2018 10:33:23 AM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":"true"},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<ul>\n  <li>사용 가능한 aggregation 함수 목록\n    <ul>\n      <li>org.apache.spark.sql.functions</li>\n      <li><a href=\"https://spark.apache.org/docs/2.0.2/api/java/org/apache/spark/sql/functions.html\">https://spark.apache.org/docs/2.0.2/api/java/org/apache/spark/sql/functions.html</a></li>\n      <li>function\n        <ul>\n          <li>abs(Column e)</li>\n          <li>stddev(Column e)</li>\n          <li>count(Column e)</li>\n          <li>variance(Column e)</li>\n          <li>max(Column e)</li>\n          <li>min(Column e)</li>\n          <li>avg(Column e)</li>\n        </ul>\n      </li>\n      <li><code>$&quot;comunm_name&quot;</code>은 Column 객체로 변환</li>\n    </ul>\n  </li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1521100725242_1824670640","id":"20180315-075845_1214666938","dateCreated":"Mar 15, 2018 7:58:45 AM","dateStarted":"Mar 15, 2018 10:33:23 AM","dateFinished":"Mar 15, 2018 10:33:23 AM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"parsed.agg(avg($\"cmp_sex\"), stddev($\"cmp_sex\")).show()","user":"anonymous","dateUpdated":"Mar 15, 2018 10:36:16 AM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":"true"},"editorMode":"ace/mode/scala","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-----------------+--------------------+\n|     avg(cmp_sex)|stddev_samp(cmp_sex)|\n+-----------------+--------------------+\n|0.955001381078048|  0.2073011111689795|\n+-----------------+--------------------+\n\n"}]},"apps":[],"jobName":"paragraph_1521101008724_1172534934","id":"20180315-080328_1909069784","dateCreated":"Mar 15, 2018 8:03:28 AM","dateStarted":"Mar 15, 2018 10:36:16 AM","dateFinished":"Mar 15, 2018 10:36:21 AM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"%md\n- Spark SQL을 사용하기 위해서 Spark SQL 엔진에 데이터 프레임 등록","user":"anonymous","dateUpdated":"Mar 15, 2018 10:37:25 AM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":"true"},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<ul>\n  <li>Spark SQL을 사용하기 위해서 Spark SQL 엔진에 데이터 프레임 등록</li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1521110176841_66568723","id":"20180315-103616_349967046","dateCreated":"Mar 15, 2018 10:36:16 AM","dateStarted":"Mar 15, 2018 10:37:25 AM","dateFinished":"Mar 15, 2018 10:37:25 AM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"parsed.createOrReplaceTempView(\"linkage\")\n","user":"anonymous","dateUpdated":"Mar 15, 2018 10:37:54 AM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"text","editOnDblClick":false},"editorMode":"ace/mode/text"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1521110245896_-554926633","id":"20180315-103725_670938749","dateCreated":"Mar 15, 2018 10:37:25 AM","dateStarted":"Mar 15, 2018 10:37:54 AM","dateFinished":"Mar 15, 2018 10:37:55 AM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"spark.sql(\"\"\"\nselect is_match, count(*) cnt\nfrom linkage \ngroup by is_match\norder by cnt desc\n\n\"\"\").show()\n","user":"anonymous","dateUpdated":"Mar 15, 2018 11:00:35 AM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"text","editOnDblClick":false},"editorMode":"ace/mode/text"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+--------+-------+\n|is_match|    cnt|\n+--------+-------+\n|   false|5728201|\n|    true|  20931|\n+--------+-------+\n\n"}]},"apps":[],"jobName":"paragraph_1521110274880_232300265","id":"20180315-103754_1417807518","dateCreated":"Mar 15, 2018 10:37:54 AM","dateStarted":"Mar 15, 2018 11:00:35 AM","dateFinished":"Mar 15, 2018 11:00:40 AM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"%md\n- spark 2.0은 ansi 2003 지원\n- hive sql 사용 가능\n- hive sql을 사용하려면 builder api에 enableHiveSupport 호출","user":"anonymous","dateUpdated":"Mar 15, 2018 11:19:25 AM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":"true"},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<ul>\n  <li>spark 2.0은 ansi 2003 지원</li>\n  <li>hive sql 사용 가능</li>\n  <li>hive sql을 사용하려면 builder api에 enableHiveSupport 호출</li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1521110295726_738107151","id":"20180315-103815_328647060","dateCreated":"Mar 15, 2018 10:38:15 AM","dateStarted":"Mar 15, 2018 11:19:25 AM","dateFinished":"Mar 15, 2018 11:19:25 AM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"val summary = parsed.describe()\nsummary.show()","user":"anonymous","dateUpdated":"Mar 15, 2018 11:21:50 AM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"text","editOnDblClick":false},"editorMode":"ace/mode/text"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nsummary: org.apache.spark.sql.DataFrame = [summary: string, id_1: string ... 10 more fields]\n+-------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+-------------------+-------------------+-------------------+-------------------+\n|summary|              id_1|              id_2|      cmp_fname_c1|      cmp_fname_c2|      cmp_lname_c1|      cmp_lname_c2|           cmp_sex|             cmp_bd|             cmp_bm|             cmp_by|            cmp_plz|\n+-------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+-------------------+-------------------+-------------------+-------------------+\n|  count|           5749132|           5749132|           5748125|            103698|           5749132|              2464|           5749132|            5748337|            5748337|            5748337|            5736289|\n|   mean| 33324.48559643438| 66587.43558331935|0.7129024704436274|0.9000176718903216|0.3156278193084134|0.3184128315317437| 0.955001381078048|0.22446526708507172|0.48885529849763504| 0.2227485966810923|0.00552866147434343|\n| stddev|23659.859374488213|23620.487613269885|0.3887583596162788|0.2713176105782331|0.3342336339615816|0.3685670662006654|0.2073011111689795| 0.4172297223846255|0.49987582367790384|0.41609096298317344|0.07414914925420066|\n|    min|                 1|                 6|               0.0|               0.0|               0.0|               0.0|                 0|                  0|                  0|                  0|                  0|\n|    max|             99980|            100000|               1.0|               1.0|               1.0|               1.0|                 1|                  1|                  1|                  1|                  1|\n+-------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+-------------------+-------------------+-------------------+-------------------+\n\n"}]},"apps":[],"jobName":"paragraph_1521112765413_-1764002556","id":"20180315-111925_922936427","dateCreated":"Mar 15, 2018 11:19:25 AM","dateStarted":"Mar 15, 2018 11:21:50 AM","dateFinished":"Mar 15, 2018 11:22:12 AM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"summary.select(\"summary\", \"cmp_fname_c1\", \"cmp_fname_c2\" ).show()","user":"anonymous","dateUpdated":"Mar 15, 2018 11:23:08 AM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-------+------------------+------------------+\n|summary|      cmp_fname_c1|      cmp_fname_c2|\n+-------+------------------+------------------+\n|  count|           5748125|            103698|\n|   mean|0.7129024704436274|0.9000176718903216|\n| stddev|0.3887583596162788|0.2713176105782331|\n|    min|               0.0|               0.0|\n|    max|               1.0|               1.0|\n+-------+------------------+------------------+\n\n"}]},"apps":[],"jobName":"paragraph_1521112775980_-57241110","id":"20180315-111935_453096434","dateCreated":"Mar 15, 2018 11:19:35 AM","dateStarted":"Mar 15, 2018 11:23:08 AM","dateFinished":"Mar 15, 2018 11:23:08 AM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"%md\n- cmp_fname_c1와 cmp_fname_c2에서 cmp_fname_c2의 건수는 20% 규모","user":"anonymous","dateUpdated":"Mar 15, 2018 11:24:36 AM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"text","editOnDblClick":false},"editorMode":"ace/mode/text","editorHide":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<ul>\n  <li>cmp_fname_c1와 cmp_fname_c2에서 cmp_fname_c2의 건수는 20% 규모</li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1521112988214_-292801027","id":"20180315-112308_1320396358","dateCreated":"Mar 15, 2018 11:23:08 AM","dateStarted":"Mar 15, 2018 11:24:29 AM","dateFinished":"Mar 15, 2018 11:24:29 AM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"val matches = parsed.where(\"is_match=true\")\nval matchSummary = matches.describe()\n\nval mismatches = parsed.filter($\"is_match\"===false)\nval misSummary = mismatches.describe()","user":"anonymous","dateUpdated":"Mar 15, 2018 11:25:59 AM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nmatches: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [id_1: int, id_2: int ... 10 more fields]\n\nmatchSummary: org.apache.spark.sql.DataFrame = [summary: string, id_1: string ... 10 more fields]\n\nmismatches: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [id_1: int, id_2: int ... 10 more fields]\n\nmisSummary: org.apache.spark.sql.DataFrame = [summary: string, id_1: string ... 10 more fields]\n"}]},"apps":[],"jobName":"paragraph_1521113069395_343897106","id":"20180315-112429_684721049","dateCreated":"Mar 15, 2018 11:24:29 AM","dateStarted":"Mar 15, 2018 11:25:59 AM","dateFinished":"Mar 15, 2018 11:26:31 AM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"matchSummary.show()","user":"anonymous","dateUpdated":"Mar 15, 2018 11:26:23 AM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-------+-----------------+------------------+--------------------+-------------------+-------------------+-------------------+-------------------+-------------------+-------------------+--------------------+-------------------+\n|summary|             id_1|              id_2|        cmp_fname_c1|       cmp_fname_c2|       cmp_lname_c1|       cmp_lname_c2|            cmp_sex|             cmp_bd|             cmp_bm|              cmp_by|            cmp_plz|\n+-------+-----------------+------------------+--------------------+-------------------+-------------------+-------------------+-------------------+-------------------+-------------------+--------------------+-------------------+\n|  count|            20931|             20931|               20922|               1333|              20931|                475|              20931|              20925|              20925|               20925|              20902|\n|   mean|34575.72117911232| 51259.95939037791|  0.9973163859635039| 0.9898900320318176| 0.9970152595958816| 0.9693701678438521|  0.987291577086618| 0.9970848267622461| 0.9979450418160095|  0.9961290322580645| 0.9584250310975027|\n| stddev|21950.31285196913|24345.733453775203|0.036506675848336785|0.08251973727615239|0.04311880753394512|0.15345280740388917|0.11201570591216432|0.05391487659807977|0.04528612745217064|0.062098048567310576|0.19962063345931927|\n|    min|                5|                 6|                 0.0|                0.0|                0.0|                0.0|                  0|                  0|                  0|                   0|                  0|\n|    max|            99946|             99996|                 1.0|                1.0|                1.0|                1.0|                  1|                  1|                  1|                   1|                  1|\n+-------+-----------------+------------------+--------------------+-------------------+-------------------+-------------------+-------------------+-------------------+-------------------+--------------------+-------------------+\n\n"}]},"apps":[],"jobName":"paragraph_1521113159431_-915496602","id":"20180315-112559_1243842730","dateCreated":"Mar 15, 2018 11:25:59 AM","dateStarted":"Mar 15, 2018 11:26:23 AM","dateFinished":"Mar 15, 2018 11:26:32 AM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"misSummary.show()","user":"anonymous","dateUpdated":"Mar 15, 2018 11:26:48 AM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-------+------------------+------------------+-------------------+------------------+------------------+-------------------+-------------------+------------------+-----------------+-------------------+--------------------+\n|summary|              id_1|              id_2|       cmp_fname_c1|      cmp_fname_c2|      cmp_lname_c1|       cmp_lname_c2|            cmp_sex|            cmp_bd|           cmp_bm|             cmp_by|             cmp_plz|\n+-------+------------------+------------------+-------------------+------------------+------------------+-------------------+-------------------+------------------+-----------------+-------------------+--------------------+\n|  count|           5728201|           5728201|            5727203|            102365|           5728201|               1989|            5728201|           5727412|          5727412|            5727412|             5715387|\n|   mean|33319.913548075565| 66643.44259218557| 0.7118634802174252|0.8988473514090173| 0.313138011336829|0.16295544855122554| 0.9548833918362851|0.2216425149788421|0.486995347986141| 0.2199230647280133|0.002043781112285135|\n| stddev|23665.760130330764|23599.551728241124|0.38908060096985714|0.2727209029401023|0.3322812130572706|0.19302366635287024|0.20755988859217656|0.4153518275558737| 0.49983089404939|0.41419432671429335| 0.04516197989362504|\n|    min|                 1|                30|                0.0|               0.0|               0.0|                0.0|                  0|                 0|                0|                  0|                   0|\n|    max|             99980|            100000|                1.0|               1.0|               1.0|                1.0|                  1|                 1|                1|                  1|                   1|\n+-------+------------------+------------------+-------------------+------------------+------------------+-------------------+-------------------+------------------+-----------------+-------------------+--------------------+\n\n"}]},"apps":[],"jobName":"paragraph_1521113183778_1295132660","id":"20180315-112623_1329355403","dateCreated":"Mar 15, 2018 11:26:23 AM","dateStarted":"Mar 15, 2018 11:26:48 AM","dateFinished":"Mar 15, 2018 11:26:48 AM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"%md\n- Pivoting: 축회전\n- Reshaping: 형태 변환","user":"anonymous","dateUpdated":"Mar 15, 2018 11:27:57 AM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":"true"},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<ul>\n  <li>Pivoting: 축회전</li>\n  <li>Reshaping: 형태 변환</li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1521113208326_440251252","id":"20180315-112648_960220097","dateCreated":"Mar 15, 2018 11:26:48 AM","dateStarted":"Mar 15, 2018 11:27:57 AM","dateFinished":"Mar 15, 2018 11:27:57 AM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"%md\n## 데이터프레임웍 축 회전 및 형태 변환","user":"anonymous","dateUpdated":"Mar 15, 2018 11:28:23 AM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":"true"},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>데이터프레임웍 축 회전 및 형태 변환</h2>\n</div>"}]},"apps":[],"jobName":"paragraph_1521113277675_-340096138","id":"20180315-112757_749853586","dateCreated":"Mar 15, 2018 11:27:57 AM","dateStarted":"Mar 15, 2018 11:28:23 AM","dateFinished":"Mar 15, 2018 11:28:24 AM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"summary.printSchema()\n","user":"anonymous","dateUpdated":"Mar 15, 2018 12:07:52 PM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"text","editOnDblClick":false},"editorMode":"ace/mode/text"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"root\n |-- summary: string (nullable = true)\n |-- id_1: string (nullable = true)\n |-- id_2: string (nullable = true)\n |-- cmp_fname_c1: string (nullable = true)\n |-- cmp_fname_c2: string (nullable = true)\n |-- cmp_lname_c1: string (nullable = true)\n |-- cmp_lname_c2: string (nullable = true)\n |-- cmp_sex: string (nullable = true)\n |-- cmp_bd: string (nullable = true)\n |-- cmp_bm: string (nullable = true)\n |-- cmp_by: string (nullable = true)\n |-- cmp_plz: string (nullable = true)\n\n"}]},"apps":[],"jobName":"paragraph_1521113303834_-1237868563","id":"20180315-112823_1816308025","dateCreated":"Mar 15, 2018 11:28:23 AM","dateStarted":"Mar 15, 2018 12:07:52 PM","dateFinished":"Mar 15, 2018 12:07:52 PM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"summary.select(\"summary\",\"id_1\", \"id_2\",\"cmp_fname_c1\" ).show()","user":"anonymous","dateUpdated":"Mar 15, 2018 10:33:41 PM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-------+------------------+------------------+------------------+\n|summary|              id_1|              id_2|      cmp_fname_c1|\n+-------+------------------+------------------+------------------+\n|  count|           5749132|           5749132|           5748125|\n|   mean| 33324.48559643438| 66587.43558331935|0.7129024704436274|\n| stddev|23659.859374488213|23620.487613269885|0.3887583596162788|\n|    min|                 1|                 6|               0.0|\n|    max|             99980|            100000|               1.0|\n+-------+------------------+------------------+------------------+\n\n"}]},"apps":[],"jobName":"paragraph_1521153141793_788460674","id":"20180315-223221_1343084975","dateCreated":"Mar 15, 2018 10:32:21 PM","dateStarted":"Mar 15, 2018 10:33:41 PM","dateFinished":"Mar 15, 2018 10:33:41 PM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"val schema = summary.schema","user":"anonymous","dateUpdated":"Mar 15, 2018 10:45:02 PM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nschema: org.apache.spark.sql.types.StructType = StructType(StructField(summary,StringType,true), StructField(id_1,StringType,true), StructField(id_2,StringType,true), StructField(cmp_fname_c1,StringType,true), StructField(cmp_fname_c2,StringType,true), StructField(cmp_lname_c1,StringType,true), StructField(cmp_lname_c2,StringType,true), StructField(cmp_sex,StringType,true), StructField(cmp_bd,StringType,true), StructField(cmp_bm,StringType,true), StructField(cmp_by,StringType,true), StructField(cmp_plz,StringType,true))\n"}]},"apps":[],"jobName":"paragraph_1521153867356_203849783","id":"20180315-224427_1541312363","dateCreated":"Mar 15, 2018 10:44:27 PM","dateStarted":"Mar 15, 2018 10:45:02 PM","dateFinished":"Mar 15, 2018 10:45:03 PM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"val longForm = summary.flatMap(row=>{\n    val matric = row.getString(0)\n    (1 until row.size).map(i=> {\n        (matric, schema(i).name, row.getString(i).toDouble)\n    })\n})\nval longDF = longForm.toDF()\nlongDF.show()","user":"anonymous","dateUpdated":"Mar 15, 2018 10:52:55 PM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"\nlongForm: org.apache.spark.sql.Dataset[(String, String, Double)] = [_1: string, _2: string ... 1 more field]\n\nlongDF: org.apache.spark.sql.DataFrame = [_1: string, _2: string ... 1 more field]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\norg.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 2164.0 failed 4 times, most recent failure: Lost task 0.3 in stage 2164.0 (TID 26929, bdc-demo-bdcsce-1.compute-gse00000548.oraclecloud.internal, executor 4): java.lang.NoClassDefFoundError: L$line18798334691/$read;\n\tat java.lang.Class.getDeclaredFields0(Native Method)\n\tat java.lang.Class.privateGetDeclaredFields(Class.java:2583)\n\tat java.lang.Class.getDeclaredField(Class.java:2068)\n\tat java.io.ObjectStreamClass.getDeclaredSUID(ObjectStreamClass.java:1803)\n\tat java.io.ObjectStreamClass.access$700(ObjectStreamClass.java:79)\n\tat java.io.ObjectStreamClass$2.run(ObjectStreamClass.java:494)\n\tat java.io.ObjectStreamClass$2.run(ObjectStreamClass.java:482)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat java.io.ObjectStreamClass.<init>(ObjectStreamClass.java:482)\n\tat java.io.ObjectStreamClass.lookup(ObjectStreamClass.java:379)\n\tat java.io.ObjectStreamClass.initNonProxy(ObjectStreamClass.java:669)\n\tat java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1880)\n\tat java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1746)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2037)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2282)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2206)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2282)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2206)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2282)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2206)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2282)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2206)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2282)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2206)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2282)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2206)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2282)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2206)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2282)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2206)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2282)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2206)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2282)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2206)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2282)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2206)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n\tat java.io.ObjectInputStream.readObject(ObjectInputStream.java:428)\n\tat scala.collection.immutable.List$SerializationProxy.readObject(List.scala:479)\n\tat sun.reflect.GeneratedMethodAccessor75.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1158)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2173)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2282)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2206)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2282)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2206)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n\tat java.io.ObjectInputStream.readObject(ObjectInputStream.java:428)\n\tat scala.collection.immutable.List$SerializationProxy.readObject(List.scala:479)\n\tat sun.reflect.GeneratedMethodAccessor75.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1158)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2173)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2282)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2206)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2282)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2206)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n\tat java.io.ObjectInputStream.readObject(ObjectInputStream.java:428)\n\tat org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:75)\n\tat org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:114)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:80)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:99)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.lang.ClassNotFoundException: $line18798334691.$read\n\tat org.apache.spark.repl.ExecutorClassLoader.findClass(ExecutorClassLoader.scala:82)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:424)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:357)\n\t... 102 more\nCaused by: java.lang.ClassNotFoundException: $line18798334691.$read\n\tat java.lang.ClassLoader.findClass(ClassLoader.java:530\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n)\n\tat org.apache.spark.util.ParentClassLoader.findClass(ParentClassLoader.scala:26)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:424)\n\tat org.apache.spark.util.ParentClassLoader.loadClass(ParentClassLoader.scala:34)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:357)\n\tat org.apache.spark.util.ParentClassLoader.loadClass(ParentClassLoader.scala:30)\n\tat org.apache.spark.repl.ExecutorClassLoader.findClass(ExecutorClassLoader.scala:77)\n\t... 104 more\n\nDriver stacktrace:\n  at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435)\n  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423)\n  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422)\n  at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n  at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n  at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422)\n  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802)\n  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802)\n  at scala.Option.foreach(Option.scala:257)\n  at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802)\n  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1650)\n  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1605)\n  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1594)\n  at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n  at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:628)\n  at org.apache.spark.SparkContext.runJob(SparkContext.scala:1925)\n  at org.apache.spark.SparkContext.runJob(SparkContext.scala:1938)\n  at org.apache.spark.SparkContext.runJob(SparkContext.scala:1951)\n  at org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:333)\n  at org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:38)\n  at org.apache.spark.sql.Dataset$$anonfun$org$apache$spark$sql$Dataset$$execute$1$1.apply(Dataset.scala:2378)\n  at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:57)\n  at org.apache.spark.sql.Dataset.withNewExecutionId(Dataset.scala:2780)\n  at org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$execute$1(Dataset.scala:2377)\n  at org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collect(Dataset.scala:2384)\n  at org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2120)\n  at org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2119)\n  at org.apache.spark.sql.Dataset.withTypedCallback(Dataset.scala:2810)\n  at org.apache.spark.sql.Dataset.head(Dataset.scala:2119)\n  at org.apache.spark.sql.Dataset.take(Dataset.scala:2334)\n  at org.apache.spark.sql.Dataset.showString(Dataset.scala:248)\n  at org.apache.spark.sql.Dataset.show(Dataset.scala:638)\n  at org.apache.spark.sql.Dataset.show(Dataset.scala:597)\n  at org.apache.spark.sql.Dataset.show(Dataset.scala:606)\n  ... 50 elided\nCaused by: java.lang.NoClassDefFoundError: L$line18798334691/$read;\n  at java.lang.Class.getDeclaredFields0(Native Method)\n  at java.lang.Class.privateGetDeclaredFields(Class.java:2583)\n  at java.lang.Class.getDeclaredField(Class.java:2068)\n  at java.io.ObjectStreamClass.getDeclaredSUID(ObjectStreamClass.java:1803)\n  at java.io.ObjectStreamClass.access$700(ObjectStreamClass.java:79)\n  at java.io.ObjectStreamClass$2.run(ObjectStreamClass.java:494)\n  at java.io.ObjectStreamClass$2.run(ObjectStreamClass.java:482)\n  at java.security.AccessController.doPrivileged(Native Method)\n  at java.io.ObjectStreamClass.<init>(ObjectStreamClass.java:482)\n  at java.io.ObjectStreamClass.lookup(ObjectStreamClass.java:379)\n  at java.io.ObjectStreamClass.initNonProxy(ObjectStreamClass.java:669)\n  at java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1880)\n  at java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1746)\n  at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2037)\n  at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n  at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2282)\n  at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2206)\n  at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n  at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n  at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2282)\n  at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2206)\n  at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n  at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n  at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2282)\n  at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2206)\n  at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n  at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n  at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2282)\n  at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2206)\n  at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n  at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n  at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2282)\n  at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2206)\n  at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n  at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n  at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2282)\n  at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2206)\n  at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n  at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n  at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2282)\n  at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2206)\n  at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n  at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n  at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2282)\n  at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2206)\n  at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n  at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n  at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2282)\n  at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2206)\n  at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n  at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n  at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2282)\n  at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2206)\n  at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n  at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n  at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2282)\n  at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2206)\n  at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n  at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n  at java.io.ObjectInputStream.readObject(ObjectInputStream.java:428)\n  at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:479)\n  at sun.reflect.GeneratedMethodAccessor75.invoke(Unknown Source)\n  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n  at java.lang.reflect.Method.invoke(Method.java:498)\n  at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1158)\n  at java.io.ObjectInputStream.readSerialData(ObjectInputStream\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n.java:2173)\n  at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n  at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n  at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2282)\n  at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2206)\n  at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n  at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n  at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2282)\n  at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2206)\n  at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n  at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n  at java.io.ObjectInputStream.readObject(ObjectInputStream.java:428)\n  at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:479)\n  at sun.reflect.GeneratedMethodAccessor75.invoke(Unknown Source)\n  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n  at java.lang.reflect.Method.invoke(Method.java:498)\n  at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1158)\n  at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2173)\n  at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n  at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n  at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2282)\n  at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2206)\n  at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n  at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n  at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2282)\n  at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2206)\n  at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n  at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n  at java.io.ObjectInputStream.readObject(ObjectInputStream.java:428)\n  at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:75)\n  at org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:114)\n  at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:80)\n  at org.apache.spark.scheduler.Task.run(Task.scala:99)\n  at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)\n  ... 3 more\nCaused by: java.lang.ClassNotFoundException: $line18798334691.$read\n  at org.apache.spark.repl.ExecutorClassLoader.findClass(ExecutorClassLoader.scala:82)\n  at java.lang.ClassLoader.loadClass(ClassLoader.java:424)\n  at java.lang.ClassLoader.loadClass(ClassLoader.java:357)\n  ... 102 more\nCaused by: java.lang.ClassNotFoundException: $line18798334691.$read\n  at java.lang.ClassLoader.findClass(ClassLoader.java:530)\n  at org.apache.spark.util.ParentClassLoader.findClass(ParentClassLoader.scala:26)\n  at java.lang.ClassLoader.loadClass(ClassLoader.java:424)\n  at org.apache.spark.util.ParentClassLoader.loadClass(ParentClassLoader.scala:34)\n  at java.lang.ClassLoader.loadClass(ClassLoader.java:357)\n  at org.apache.spark.util.ParentClassLoader.loadClass(ParentClassLoader.scala:30)\n  at org.apache.spark.repl.ExecutorClassLoader.findClass(ExecutorClassLoader.scala:77)\n  ... 104 more\n"}]},"apps":[],"jobName":"paragraph_1521152714259_-1564508713","id":"20180315-222514_592329206","dateCreated":"Mar 15, 2018 10:25:14 PM","dateStarted":"Mar 15, 2018 10:52:55 PM","dateFinished":"Mar 15, 2018 10:52:56 PM","status":"ERROR","progressUpdateIntervalMs":500},{"text":"val schema = summary.schema\nval longForm = summary.flatMap(row=>{\n    val matric = row.getString(0)\n    (1 until row.size).map(i=> {\n        (matric, schema(i).name, row.getString(i).toDouble)\n    })\n})\nval longDF = longForm.toDF()\nlongDF.show()","user":"anonymous","dateUpdated":"Mar 15, 2018 12:44:47 PM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"\nschema: org.apache.spark.sql.types.StructType = StructType(StructField(summary,StringType,true), StructField(id_1,StringType,true), StructField(id_2,StringType,true), StructField(cmp_fname_c1,StringType,true), StructField(cmp_fname_c2,StringType,true), StructField(cmp_lname_c1,StringType,true), StructField(cmp_lname_c2,StringType,true), StructField(cmp_sex,StringType,true), StructField(cmp_bd,StringType,true), StructField(cmp_bm,StringType,true), StructField(cmp_by,StringType,true), StructField(cmp_plz,StringType,true))\n\nlongForm: org.apache.spark.sql.Dataset[(String, String, Double)] = [_1: string, _2: string ... 1 more field]\n\nlongDF: org.apache.spark.sql.DataFrame = [_1: string, _2: string ... 1 more field]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\norg.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 2150.0 failed 4 times, most recent failure: Lost task 0.3 in stage 2150.0 (TID 26881, bdc-demo-bdcsce-1.compute-gse00000548.oraclecloud.internal, executor 10): java.lang.NoClassDefFoundError: L$line18798334691/$read;\n\tat java.lang.Class.getDeclaredFields0(Native Method)\n\tat java.lang.Class.privateGetDeclaredFields(Class.java:2583)\n\tat java.lang.Class.getDeclaredField(Class.java:2068)\n\tat java.io.ObjectStreamClass.getDeclaredSUID(ObjectStreamClass.java:1803)\n\tat java.io.ObjectStreamClass.access$700(ObjectStreamClass.java:79)\n\tat java.io.ObjectStreamClass$2.run(ObjectStreamClass.java:494)\n\tat java.io.ObjectStreamClass$2.run(ObjectStreamClass.java:482)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat java.io.ObjectStreamClass.<init>(ObjectStreamClass.java:482)\n\tat java.io.ObjectStreamClass.lookup(ObjectStreamClass.java:379)\n\tat java.io.ObjectStreamClass.initNonProxy(ObjectStreamClass.java:669)\n\tat java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1880)\n\tat java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1746)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2037)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2282)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2206)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2282)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2206)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2282)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2206)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2282)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2206)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2282)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2206)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2282)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2206)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2282)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2206)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2282)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2206)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2282)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2206)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2282)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2206)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2282)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2206)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n\tat java.io.ObjectInputStream.readObject(ObjectInputStream.java:428)\n\tat scala.collection.immutable.List$SerializationProxy.readObject(List.scala:479)\n\tat sun.reflect.GeneratedMethodAccessor75.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1158)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2173)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2282)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2206)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2282)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2206)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n\tat java.io.ObjectInputStream.readObject(ObjectInputStream.java:428)\n\tat scala.collection.immutable.List$SerializationProxy.readObject(List.scala:479)\n\tat sun.reflect.GeneratedMethodAccessor75.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1158)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2173)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2282)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2206)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2282)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2206)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n\tat java.io.ObjectInputStream.readObject(ObjectInputStream.java:428)\n\tat org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:75)\n\tat org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:114)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:80)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:99)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.lang.ClassNotFoundException: $line18798334691.$read\n\tat org.apache.spark.repl.ExecutorClassLoader.findClass(ExecutorClassLoader.scala:82)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:424)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:357)\n\t... 102 more\nCaused by: java.lang.ClassNotFoundException: $line18798334691.$read\n\tat java.lang.ClassLoader.findClass(ClassLoader.java:53\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0)\n\tat org.apache.spark.util.ParentClassLoader.findClass(ParentClassLoader.scala:26)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:424)\n\tat org.apache.spark.util.ParentClassLoader.loadClass(ParentClassLoader.scala:34)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:357)\n\tat org.apache.spark.util.ParentClassLoader.loadClass(ParentClassLoader.scala:30)\n\tat org.apache.spark.repl.ExecutorClassLoader.findClass(ExecutorClassLoader.scala:77)\n\t... 104 more\n\nDriver stacktrace:\n  at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435)\n  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423)\n  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422)\n  at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n  at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n  at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422)\n  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802)\n  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802)\n  at scala.Option.foreach(Option.scala:257)\n  at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802)\n  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1650)\n  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1605)\n  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1594)\n  at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n  at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:628)\n  at org.apache.spark.SparkContext.runJob(SparkContext.scala:1925)\n  at org.apache.spark.SparkContext.runJob(SparkContext.scala:1938)\n  at org.apache.spark.SparkContext.runJob(SparkContext.scala:1951)\n  at org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:333)\n  at org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:38)\n  at org.apache.spark.sql.Dataset$$anonfun$org$apache$spark$sql$Dataset$$execute$1$1.apply(Dataset.scala:2378)\n  at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:57)\n  at org.apache.spark.sql.Dataset.withNewExecutionId(Dataset.scala:2780)\n  at org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$execute$1(Dataset.scala:2377)\n  at org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collect(Dataset.scala:2384)\n  at org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2120)\n  at org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2119)\n  at org.apache.spark.sql.Dataset.withTypedCallback(Dataset.scala:2810)\n  at org.apache.spark.sql.Dataset.head(Dataset.scala:2119)\n  at org.apache.spark.sql.Dataset.take(Dataset.scala:2334)\n  at org.apache.spark.sql.Dataset.showString(Dataset.scala:248)\n  at org.apache.spark.sql.Dataset.show(Dataset.scala:638)\n  at org.apache.spark.sql.Dataset.show(Dataset.scala:597)\n  at org.apache.spark.sql.Dataset.show(Dataset.scala:606)\n  ... 50 elided\nCaused by: java.lang.NoClassDefFoundError: L$line18798334691/$read;\n  at java.lang.Class.getDeclaredFields0(Native Method)\n  at java.lang.Class.privateGetDeclaredFields(Class.java:2583)\n  at java.lang.Class.getDeclaredField(Class.java:2068)\n  at java.io.ObjectStreamClass.getDeclaredSUID(ObjectStreamClass.java:1803)\n  at java.io.ObjectStreamClass.access$700(ObjectStreamClass.java:79)\n  at java.io.ObjectStreamClass$2.run(ObjectStreamClass.java:494)\n  at java.io.ObjectStreamClass$2.run(ObjectStreamClass.java:482)\n  at java.security.AccessController.doPrivileged(Native Method)\n  at java.io.ObjectStreamClass.<init>(ObjectStreamClass.java:482)\n  at java.io.ObjectStreamClass.lookup(ObjectStreamClass.java:379)\n  at java.io.ObjectStreamClass.initNonProxy(ObjectStreamClass.java:669)\n  at java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1880)\n  at java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1746)\n  at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2037)\n  at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n  at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2282)\n  at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2206)\n  at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n  at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n  at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2282)\n  at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2206)\n  at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n  at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n  at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2282)\n  at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2206)\n  at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n  at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n  at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2282)\n  at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2206)\n  at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n  at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n  at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2282)\n  at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2206)\n  at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n  at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n  at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2282)\n  at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2206)\n  at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n  at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n  at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2282)\n  at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2206)\n  at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n  at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n  at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2282)\n  at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2206)\n  at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n  at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n  at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2282)\n  at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2206)\n  at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n  at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n  at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2282)\n  at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2206)\n  at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n  at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n  at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2282)\n  at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2206)\n  at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n  at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n  at java.io.ObjectInputStream.readObject(ObjectInputStream.java:428)\n  at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:479)\n  at sun.reflect.GeneratedMethodAccessor75.invoke(Unknown Source)\n  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n  at java.lang.reflect.Method.invoke(Method.java:498)\n  at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1158)\n  at java.io.ObjectInputStream.readSerialData(ObjectInputStrea\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nm.java:2173)\n  at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n  at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n  at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2282)\n  at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2206)\n  at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n  at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n  at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2282)\n  at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2206)\n  at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n  at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n  at java.io.ObjectInputStream.readObject(ObjectInputStream.java:428)\n  at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:479)\n  at sun.reflect.GeneratedMethodAccessor75.invoke(Unknown Source)\n  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n  at java.lang.reflect.Method.invoke(Method.java:498)\n  at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1158)\n  at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2173)\n  at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n  at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n  at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2282)\n  at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2206)\n  at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n  at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n  at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2282)\n  at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2206)\n  at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2064)\n  at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1568)\n  at java.io.ObjectInputStream.readObject(ObjectInputStream.java:428)\n  at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:75)\n  at org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:114)\n  at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:80)\n  at org.apache.spark.scheduler.Task.run(Task.scala:99)\n  at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)\n  ... 3 more\nCaused by: java.lang.ClassNotFoundException: $line18798334691.$read\n  at org.apache.spark.repl.ExecutorClassLoader.findClass(ExecutorClassLoader.scala:82)\n  at java.lang.ClassLoader.loadClass(ClassLoader.java:424)\n  at java.lang.ClassLoader.loadClass(ClassLoader.java:357)\n  ... 102 more\nCaused by: java.lang.ClassNotFoundException: $line18798334691.$read\n  at java.lang.ClassLoader.findClass(ClassLoader.java:530)\n  at org.apache.spark.util.ParentClassLoader.findClass(ParentClassLoader.scala:26)\n  at java.lang.ClassLoader.loadClass(ClassLoader.java:424)\n  at org.apache.spark.util.ParentClassLoader.loadClass(ParentClassLoader.scala:34)\n  at java.lang.ClassLoader.loadClass(ClassLoader.java:357)\n  at org.apache.spark.util.ParentClassLoader.loadClass(ParentClassLoader.scala:30)\n  at org.apache.spark.repl.ExecutorClassLoader.findClass(ExecutorClassLoader.scala:77)\n  ... 104 more\n"}]},"apps":[],"jobName":"paragraph_1521115672160_-2126467789","id":"20180315-120752_87393505","dateCreated":"Mar 15, 2018 12:07:52 PM","dateStarted":"Mar 15, 2018 12:44:47 PM","dateFinished":"Mar 15, 2018 12:44:49 PM","status":"ERROR","progressUpdateIntervalMs":500},{"text":"%python\n1+1","user":"anonymous","dateUpdated":"Mar 15, 2018 11:01:49 PM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"text","editOnDblClick":false},"editorMode":"ace/mode/text"},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"paragraph_1521117610159_1408360442's Interpreter python not found"}]},"apps":[],"jobName":"paragraph_1521117610159_1408360442","id":"20180315-124010_2015589660","dateCreated":"Mar 15, 2018 12:40:10 PM","status":"ERROR","errorMessage":"","progressUpdateIntervalMs":500},{"text":"%sh\npython --version","user":"anonymous","dateUpdated":"Mar 15, 2018 11:05:02 PM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"sh","editOnDblClick":"false"},"editorMode":"ace/mode/sh","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Python 2.6.6\n"}]},"apps":[],"jobName":"paragraph_1521154909586_-919912575","id":"20180315-230149_2105423961","dateCreated":"Mar 15, 2018 11:01:49 PM","dateStarted":"Mar 15, 2018 11:05:02 PM","dateFinished":"Mar 15, 2018 11:05:02 PM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"%sh\npython3 --version","user":"anonymous","dateUpdated":"Mar 15, 2018 11:05:14 PM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"sh","editOnDblClick":"false"},"editorMode":"ace/mode/sh","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"bash: python3: command not found\n"},{"type":"TEXT","data":"ExitValue: 127"}]},"apps":[],"jobName":"paragraph_1521155101993_-2079501432","id":"20180315-230501_23776637","dateCreated":"Mar 15, 2018 11:05:01 PM","dateStarted":"Mar 15, 2018 11:05:14 PM","dateFinished":"Mar 15, 2018 11:05:14 PM","status":"ERROR","progressUpdateIntervalMs":500},{"text":"%sh\nwhich python","user":"anonymous","dateUpdated":"Mar 15, 2018 11:05:30 PM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"sh","editOnDblClick":"false"},"editorMode":"ace/mode/sh","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"/usr/bin/python\n"}]},"apps":[],"jobName":"paragraph_1521155114608_1505450902","id":"20180315-230514_707421684","dateCreated":"Mar 15, 2018 11:05:14 PM","dateStarted":"Mar 15, 2018 11:05:30 PM","dateFinished":"Mar 15, 2018 11:05:30 PM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"%sh\nls -al /usr/bin/python","user":"anonymous","dateUpdated":"Mar 15, 2018 11:05:45 PM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"sh","editOnDblClick":"false"},"editorMode":"ace/mode/sh","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"-rwxr-xr-x. 2 root root 4864 Aug 18  2016 /usr/bin/python\n"}]},"apps":[],"jobName":"paragraph_1521155130455_-295158626","id":"20180315-230530_1178659023","dateCreated":"Mar 15, 2018 11:05:30 PM","dateStarted":"Mar 15, 2018 11:05:45 PM","dateFinished":"Mar 15, 2018 11:05:45 PM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"%sql\nselect count(*) from linkage\n","user":"anonymous","dateUpdated":"Mar 16, 2018 3:16:29 AM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"text","editOnDblClick":false},"editorMode":"ace/mode/text"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"count(1)\n5749132\n"}]},"apps":[],"jobName":"paragraph_1521155145294_-1288965035","id":"20180315-230545_1766768975","dateCreated":"Mar 15, 2018 11:05:45 PM","dateStarted":"Mar 16, 2018 3:16:29 AM","dateFinished":"Mar 16, 2018 3:16:32 AM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"%sql\n","user":"anonymous","dateUpdated":"Mar 16, 2018 3:16:29 AM","config":{},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1521170189668_-219555647","id":"20180316-031629_1275641067","dateCreated":"Mar 16, 2018 3:16:29 AM","status":"READY","progressUpdateIntervalMs":500}],"name":"/tw/spark-study/ch02","id":"2DAY8RCRB","angularObjects":{"2D4RYE7EA:shared_process":[],"2D777G15V:shared_process":[],"2D5ZR6Y37:shared_process":[],"2D5BB7YT5:shared_process":[],"2D7ZYKW43:shared_process":[],"2D5G9XYBT:shared_process":[],"2C4U48MY3_spark2:shared_process":[],"2D7ANCEZK:shared_process":[]},"config":{},"info":{}}